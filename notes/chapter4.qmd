---
engine: knitr
---
# Probabilities with More than One Event
## Marginal and Joint Probabilities
Up until this point we have primarily focused on assigning probabilities to particular events. If we have some event of interest, $A$, then $P(A)$ is the probability that $A$ occurs in any manner. If we are using our equally likely probability model, then $P(A) = \dfrac{N_A}{N}$. This is the probability of the event $A$ where nothing else is known at all. If we smooth over anything which could alter the likelihood, if we have no additional information, if we want the best guess for the likelihood of occurrence in a vacuum, this is the probability of interest. We refer to such quantities as marginal probabilities. 

:::{#def-marginal-probability}
## Marginal Probability
The marginal probability of a single event, $A$, is the probability that the event happens without considering any additional information. This is the probability that the event happens, denoted $P(A)$.
:::

It is useful to specifically call these marginal probabilities to differentiate them from probabilities which depend on two or more events. Specifically, we can think about taking the intersection of two events, say $A \cap B$. In words this is the event that $A$ occurs **and** $B$ occurs. Until this point we have thought about solving for probabilities related to intersections as a two-step procedure: first, find an event $C = A \cap B$, and then second solve for the marginal probability of $C$. While this is a useful technique for calculation, sometimes it is more useful to think of the probability of the intersection as the probability of $A$ and $B$ occurring simultaneously. We call this the joint probability of $A$ and $B$.

:::{#def-joint-probability}
## Joint Probability
The joint probability of two events, $A$ and $B$, is given by the probability of their intersection. That is, $P(A\cap B)$. This is sometimes denoted $P(A,B)$ and corresponds to the probability that both $A$ and $B$ occur. 

The joint probability of more than two events extends in the same way. Suppose there exists a sequence of events, $A_1, \dots, A_n$, then the joint probability of these events is $$P(A_1,A_2,\dots,A_n) = P\left(\bigcap_{i=1}^n A_i\right).$$
:::

## What are Conditional Probabilities?
Marginal probabilities are often of interest, and frequently are the best tool for summarizing the overall state of the world, or our knowledge regarding the state of the world. Joint probabilities can be useful when working with compound events, or thinking of complex outcomes. However, there are many scenarios which are not covered by either the joint or marginal probabilities. In practice, we know that sometimes information that we have will change our understanding of the probability of an event. 

Suppose the event $A$ corresponds to the event that it snows tomorrow, in some particular city. It is possible to think about how often it snows on average, and report a value related to that as $P(A)$. Now, what if we know that it is currently the middle of summer, and the city is in the Northern Hemisphere? In this case, while $P(A)$ does not shrink to $0$, it becomes far less likely than if we did not have that information. Similarly, if we know that it is winter in the same city, the likelihood that it snows tomorrow increases. In order to formally capture this we can introduce the idea of conditional probability. 

:::{#def-conditional-probability}
## Conditional Probability
The conditional probability of an event $A$ given an event $B$, is the probability that $A$ occurs assuming that we know that $B$ occurs. The conditional probability takes into account additional information codified through the occurrence of an additional event. We write this quantity as $P(A|B)$, and will read this as "the probability of $A$ given $B$."
:::

Unlike in the case of marginal probabilities, conditional probabilities allow us to *condition* on extra pieces of information. Instead of asking "what is the probability of this event", we instead ask, "given that we know this piece of information, what is the probability of this event?" Joint probabilities ask "what is the probability that both of these events occur simultaneously" which is distinct in that we do not have any additional information about the state of the world when working with joint probabilities. The subtle distinction becomes quite powerful, both in terms of manipulating and working with probabilities, but also in terms of expressing the correct events of interest for ourselves. 

To make use of conditional probabilities, we will think of the process of *conditioning* on one or more events. We will talk of the probability of $A$ conditional on $B$, where $A$ and $B$ are two events of interest. Intuitively, this is the probability of $A$ happening, supposing that we know that $B$ has already happened. 

:::{#exm-basic-conditional-probability}
## Six from the Sum
Charles and Sadie are playing a new game using two dice. In the game they each take turns rolling the two dice into a container that the other player cannot see. They add up the dice and then report this sum to the other player. The other player then has to guess whether there is a six showing.

a. On one round, Charles does not hear the sum that Sadie reports as he was not paying attention. Sadie is strict and insists that she will not repeat herself. What should Charles guess?
b. Determine a strategy which optimizes the likelihood that the guessing player will be correct.

::::{.callout .solution collapse='true'}
## Solution
a. In this case we want the **marginal probability** of a six showing up on the roll of two dice. Take $E$ to represent the event wherein at least one six is showing on the roll of two dice. Thus, $E^C$ is the event that no sixes are showing. There are $5\times 5=25$ (using the product rule for counting) ways of *not* rolling a $6$, meaning that $$P(E^C) = \dfrac{25}{36} \implies P(E) = 1 - \dfrac{25}{36} = \dfrac{11}{36}.$$ Thus, Charles should guess that there is no $6$ as the probability is only $11/36 \approx 0.31$.

b.  Here we wish to determine conditional probabilities. We take $E$ to be the event that at least one $6$ is showing, and then $S$ to be a variable representing the sum of the two dice. For $s= 1, \dots, 12$ we wish to find $P(E|\{S=s\})$. Notice that for $s=2,\dots,6$ $P(E|S=s) = 0$. If the sum is $2$ we know that there could not have been a $6$. Moreover, for $s=11,12$ we know that $P(E|S=s) = 1$ since the only way to form $11$ is a five and a six, and the only way to form $12$ is to have two sixes. This leaves $s = 7,\dots,10$ to check. The following table gives the set of values, the possible combinations to reach the value, and then the combinations that end up involving a $6$. 
    
    | Value | Combinations                            | Involving 6   |
    |-------|-----------------------------------------|---------------|
    | 7     | (1,6) (2,5) (3, 4) (4, 3) (5, 2) (6, 1) | (1, 6) (6, 1) |
    | 8     | (2,6) (3,5) (4, 4) (5, 3) (6, 2)        | (2, 6) (6, 2) |
    | 9     | (3,6) (4,5) (5, 4) (6, 3)               | (2, 6) (6, 2) |
    | 10    | (4, 6) (5, 5) (6, 4)                    | (4, 6) (6, 4) |

    Referencing from this table we can read off the following probabilities \begin{align*}
P(E|S=7) &= \dfrac{2}{6} = \dfrac{1}{3}\\
P(E|S=8) &= \dfrac{2}{5} \\
P(E|S=9) &= \dfrac{2}{4} \\
P(E|S=10) &= \dfrac{2}{3}.
\end{align*} As a result, the best strategy is to guess "yes" when a $10$, $11$, or $12$ is rolled and to be indifferent to the guess when a $9$ is rolled. Otherwise, guess "no."
::::
:::

Recall that $A$ and $B$, as events, are merely subsets of the sample space, $\mathcal{S}$. Each item in either $A$ or $B$ is one of the possible outcomes from the experiment or process that we are observing. Suppose that we know that $B$ has occurred. What this means is that, one of the outcomes in the set $B$ was the observed outcome from the experiment. Now, if we want to know $P(A|B)$, we want to know the probability, working from the assumption that $B$ has happened, that $A$ also happens. That is, knowing that $B$ has happened, what is the probability that $A$ and $B$ both happen. 

The event that $A$ and $B$ both happen is denoted by the intersection, $A \cap B$. This corresponds to the set of events inside the set $B$ which also belong to the set $A$. Now, instead of considering the joint probability directly, we need to acknowledge that for $A|B$, only the events in $B$ were possible. That is, instead of being divided by the whole space, we can only divide by the space of $B$. In some sense, we can view conditioning on $B$ as treating $B$ as though it is the full sample space, and finding probabilities within that. In general, $B$ will be smaller than $\mathcal{S}$, and so $P(B) < 1$. Instead of the conditional probability being "out of" $1$, it will instead be "out of" $P(B)$, which gives $P(A|B) = \dfrac{P(A\cap B)}{P(B)}$.

:::{.callout-tip icon="false"}
## Computing Conditional Probabilities
For an event $A$, and an event $B$ with probability $P(B) > 0$, the conditional probability of $A$ given $B$ is $$P(A|B) = \dfrac{P(A\cap B)}{P(B)}.$$
:::

To make this more clear, suppose that we take $A$ to be the event that a $2$ is rolled on a fair, six-sided die, and $B$ to be the event that an even number was rolled. This is an equal probability model, and so each outcome gets $\dfrac{1}{6}$ probability. The original sample space is $\mathcal{S} = \{1,2,3,4,5,6\}$, the event $A$ is $\{2\}$, and the event $B$ is $\{2,4,6\}$. In order for both $A$ and $B$ to occur, we note that we need $A \cap B = \{2\}$. If we know that $B$ has occurred, then we know that either a $2$, $4$, or $6$ has been rolled, with equal probability for each. Thus, intuitively, we can view $B$ as the new sample space, and say that rolling a $2$ has a $\dfrac{1}{3}$ probability, given that there are $3$ outcomes and $1$ of them is the event of interest. 

We can also compute this directly. Note that $P(B) = \dfrac{1}{2}$, and so we need to scale each event by $\dfrac{1}{1/2}$ in order to make sure that the total probability of our reduced sample space equals $1$. Then $P(A\cap B) = \dfrac{1}{6}$, so $$P(A|B) = \dfrac{1/6}{1/2} = \dfrac{1}{3}.$$

Suppose that, instead of a fair die, it was weighted so that $6$ comes up more frequently than the other options. Consider the probability of observing a six to be $0.5$, with the other five values each coming up with probability $0.10$. If $A$ and $B$ are the same events as above, then $P(B) = 0.7$. 

If we know that $B$ has occurred then the new sample space is $\{2,4,6\}$ where $P(2) = \dfrac{0.1}{0.7} = \dfrac{1}{7}$, $P(4) = \dfrac{0.1}{0.7} = \dfrac{1}{7}$, and $P(6) = \dfrac{0.5}{0.7} = \dfrac{5}{7}$. Note that these three probabilities sum to $1$ still, which constitutes a valid probability model, and so $P(A|B) = \dfrac{1}{7}$.

:::{#exm-basic-conditional-probability-rev}
## Six from the Sum - Revisited
Sadie sees the solution worked out for the best strategy in the dice game above, but is having trouble understanding it in the context of conditional probability more broadly. For the sums $7, 8, 9$, and $10$, describe the process of limiting the sample space to get the correct conditional probability, and use the formula to show that the probabilities worked out in @exm-basic-conditional-probability are correct.

::::{.callout .solution collapse='true'}
## Solution
The relevant table of solutions is copied from above. 

| Value | Combinations                            | Involving 6   |
|-------|-----------------------------------------|---------------|
| 7     | (1,6) (2,5) (3, 4) (4, 3) (5, 2) (6, 1) | (1, 6) (6, 1) |
| 8     | (2,6) (3,5) (4, 4) (5, 3) (6, 2)        | (2, 6) (6, 2) |
| 9     | (3,6) (4,5) (5, 4) (6, 3)               | (2, 6) (6, 2) |
| 10    | (4, 6) (5, 5) (6, 4)                    | (4, 6) (6, 4) |

Here, given a sum, we **know** that one of the events listed under "combinations" has occurred. As a result, once we have conditioned on what the sum is, we are able to treat the "combinations" column as the full sample space of possible outcomes. Each of these in this case is equally likely, and so we can divide the number which contain a $6$, by the total number in the reduced sample space.

To do this algebraically, we first note that \begin{align*}
    P(S=7) &= \dfrac{6}{36} \\
    P(S=8) &= \dfrac{5}{36} \\
    P(S=9) &= \dfrac{4}{36} \\
    P(S=10) &= \dfrac{3}{36}.
\end{align*} Now, suppose we consider the event $E\cap\{S=7\}$. This is the set $\{(1,6),(6,1)\}$ and so $P(E\cap\{S=7\}) = 2/36$. In fact, the same holds true for all of the joint events. As a result, we get \begin{align*}
    P(E|S=7) &= \dfrac{\dfrac{2}{36}}{\dfrac{6}{36}} = \dfrac{2}{6} \\
    P(E|S=8) &= \dfrac{\dfrac{2}{36}}{\dfrac{5}{36}} = \dfrac{2}{5} \\
    P(E|S=9) &= \dfrac{\dfrac{2}{36}}{\dfrac{4}{36}} = \dfrac{2}{4} \\
    P(E|S=10) &= \dfrac{\dfrac{2}{36}}{\dfrac{3}{36}} = \dfrac{2}{3}.
\end{align*} This corresponds exactly to the values we found before.
::::
:::

Sometimes, we wish to condition on more than one event. To do so, the same process extends naturally. For instance, suppose we want to know the probability of $A$ given $B$ and $C$. This would be written $$P(A|B,C) = \dfrac{P(A\cap B\cap C)}{P(B \cap C)} = \dfrac{P(A,B,C)}{P(B,C)}.$$ Moving beyond two events occurs in the expected way.

## Using Conditional Probabilities
Conditional probability is a mechanism for capturing our knowledge of the world, and using that to update our sense of the uncertainties at play. For instance, suppose that we are interested in drawing a random card from a deck of $52$, and we want to know the probability that it is a heart. Without any additional knowledge, the probability of this event is $\dfrac{1}{4}$. Now, suppose that you know that it is a red card. In this case, we now know that it is either a heart or a diamond, and there are equal numbers of each, meaning that the new probability is $0.5$. We can work this out directly $$P(\text{Heart}|\text{Red}) = \dfrac{P(\text{Heart},\text{Red})}{P(\text{Red})} = \dfrac{P(\text{Heart})}{1/2} = \dfrac{1/4}{1/2} = 0.5.$$ Suppose instead that we had been told that the card was an ace. Here we now know that there are four possible outcomes that correspond to an ace, and only one of these is a heart, meaning the probability is $\dfrac{1}{4}$. In this case, $P(A|B) = P(A)$, and our beliefs did not update.

What if instead we had considered the second event to be "the card was a spade." In this case if we want to know $P(A|B)$ then, given a spade being drawn, we know that the probability of drawing a heart is $0$. 

:::{#exm-conditional-probability-urn}
## Charles's Mismatched Urn Mishap
Charles's love of probability prompts a spontaneous decision: buy an urn and some coloured balls to fill it up with. Unfortunately, the supplier of the balls misunderstood the request and sent over an assortment of different shapes rather than just spheres. There are some spheres, some cubes, some pyramids, and some cones. There are also five different colours present, red, blue, green, yellow, and black. Charles is slightly dismayed as, when reaching into the urn, it is very easy to feel what shape you are pulling out before you see the object, and the distribution of colour-shape combinations is not even. Despite the dismay, Charles shows Sadie, who is deeply excited, explaining how this mismatched urn is perfect for understanding conditional probabilities deeply. The distribution of shapes and colours is presented in the following table.

| **Colour** | **Sphere** | **Cube** | **Pyramid** | **Cone** |
|-|:--:|:--:|:--:|:--:|
| **Red**    | 2          | 3        | 2           | 0        |
| **Blue**   | 1          | 0        | 0           | 6        |
| **Green**  | 2          | 2        | 1           | 2        |
| **Yellow** | 0          | 4        | 2           | 1        |
| **Black**  | 3          | 1        | 1           | 2        |

a. What is the probability of drawing each colour, if items are selected at random, without knowledge of the shape?
b. Assuming that the shape is known, what is the probability of selecting each colour?

::::{.callout .solution collapse='true'}
## Solution
a. Note that there are $2+3+2=7$ red, $1+6=7$ blue, $2+2+1+2=7$ green, $4+2+1=7$ yellow, and $3+1+1+2=7$ black objects. As a result, each colour is going to be equally likely, with a probability of $0.2$.

b.  Take $S$, $C$, $P$, $Cn$ to be the events that a sphere, cube, pyramid, or cone are drawn, respectively. Take $R$, $B$, $G$, $Y$, $Bk$ to be the events that a red, blue, green, yellow, or black object is drawn, respectively. We want the probability of each colour, given the corresponding shape. There are a total of $20$ conditional probabilities to solve for here. We walk through, in full, the first conditional probability calculation. After, the same process follows to get the (provided) answer. 

    First note that there are $8$ spheres, $10$ cubes, $6$ pyramids, and $11$ cones. Thus, the marginal probabilities are $P(S) = 8/35$, $P(C) = 10/35$, $P(P) = 6/35$, and $P(Cn) = 11/35$. Note further that the joint probability between any colour-shape combination is going to be given by the number of that combination that exist, divided by $35$. Thus, suppose we want $P(R|S)$. There are $2$ red spheres, so $P(R \cap S) = 2/35$. The marginal probability $P(S) = 8/35$, so taken together this gives $$P(R|S) = \dfrac{2/35}{8/35} = \dfrac{2}{8} = \dfrac{1}{4}.$$

    Applying the same process gives the following probabilities, reported in the table for convenience.

    | **Colour** | **Sphere**                  | **Cube**     | **Pyramid** | **Cone**     |
    |-|:--:|:--:|:--:|:--:|
    | **Red**    | $\dfrac{2}{8} = \dfrac{1}{4}$ |$\dfrac{3}{10}$|$\dfrac{1}{3}$|$0$           |
    | **Blue**   | $\dfrac{1}{8}$               |$0$           |$0$          |$\dfrac{6}{11}$|
    | **Green**  | $\dfrac{2}{8} = \dfrac{1}{4}$ |$\dfrac{1}{5}$ |$\dfrac{1}{6}$|$\dfrac{2}{11}$|
    | **Yellow** | $0$                         |$\dfrac{2}{5}$ |$\dfrac{1}{3}$|$\dfrac{1}{11}$|
    | **Black**  | $\dfrac{3}{8}$               |$\dfrac{1}{10}$|$\dfrac{1}{6}$|$\dfrac{2}{11}$|
::::
:::

### The Multiplication Rule
While sometimes we will want to work out the conditional probability using our knowledge of the joint and marginal probabilities, there are other times when it is easier to determine the conditional probability directly. In these settings we may wish to understand the marginal or joint probabilities. That is, we may know $P(A|B)$, but we want to make statements regarding $P(A)$ or $P(A,B)$.

To do so, we can rearrange the defining relationship of conditional probability, to solve for the quantities of interest. Because of the importance of this procedure, we actually give this mostly straightforward rearrangement a special name. 

:::{.callout-tip icon="false"}
## Multiplication Rule
The multiplication rule states that, for two events $A$ and $B$ where $P(B) > 0$, $$P(A\cap B) = P(A|B)P(B).$$ 
:::

Note that, by multiplying both sides of the definition of $P(A|B)$ by $P(B)$ gives the result. In words, it states that we can solve for the joint probability of $A$ and $B$ by multiplying the conditional probability of $A$ given $B$, by the marginal probability of $B$. This is symmetric in $A$ and $B$ so that $$P(A\cap B) = P(B|A)P(A).$$ This is useful as sometimes it is easier to determine $B$ given $A$. 

:::{#exm-package-delivery-times}
## Package Delivery Times
To thank Sadie for the help in seeing the silver lining with the urn mishap, Charles decides to order a small gift online, sending it direct to Sadie. Unfortunately, the website does not list which delivery company each package is sent out with. After some sleuthing, Charles determines that there are two different companies that it may have been sent with. Looking at online reviews it appears as though company $A$ is late $75\%$ of the time while company $B$ is late $15\%$ of the time. 

If the store that Charles ordered from sends out $10\%$ of packages with company $A$, and the rest with company $B$, which is more likely: that the package is late and was sent with $A$, or that the package was late and sent with $B$?

::::{.callout .solution collapse='true'}
## Solution
We will take $L$ to correspond to the events where the package is late, $A$ to the events where the package was sent with $A$ and $B$ to be the events where the package was sent with $B$. We wish to compare $P(L, A)$ and $P(L, B)$. We know that $P(A) = 0.1$ and $P(B) = 0.9$, and we know that $P(L|A) = 0.75$ and $P(L|B) = 0.15$. As a result, we can use the multiplication rule to find the joint probabilities. 

First, $$P(L, A) = P(L|A)P(A) = (0.75)(0.1) = 0.075.$$ Additionally, $$P(L, B) = P(L|B)P(B) = (0.15)(0.9) = 0.135.$$ 

As a result it is more likely to have the package late and sent with $B$ than to have the package late and sent with $A$.^[Note, this is another result which seems to (on the surface) defy expectations. We will see this again later on in this chapter in a slightly different context. It seems strange that company $A$ is more likely to be late, and yet, we are more likely to see a late package that is sent by company $B$ than a late package that is sent by company $A$. The reason for this is that company $B$ is used much more frequently than company $A$, which overcomes the added likelihood of company $A$ being late.]
::::
:::

### Partitions and the Law of Total Probability
While the multiplication rule gives us the capacity to solve for joint probabilities, often we wish to make statements regarding marginal probabilities. Fortunately, we can extend the process outlined in the multiplication rule to solve directly for marginal probabilities as well. To do so, we first introduce the concept of a partition.

:::{#def-partition}
## Partition
A partition is a collection of sets which divide up the sample space such that all the sets are disjoint from one another, and the sample space is given by the union of all the sets. That is, $A_1,\dots,A_n$ is a partition of $\mathcal{S}$ if:

1. $A_i \cap A_j = \emptyset$ for all $i \neq j$, and 
2. $$\bigcup_{i=1}^n A_i = \mathcal{S}.$$
:::

For instance, if the sample space were all the positive integers, we could partition this space into all the even numbers as one set and all the odd numbers as a second. We could also partition this into the set of numbers which are less than $10$, the set of numbers that are greater than $10$, and then $10$. In both examples we have sets whose union forms the full sample space with no overlap. Note that we could not partition the set into multiples of $2$ and multiples of $3$, since (i) not all values are contained between these two sets,^[For instance, $5$ is neither a multiple of $2$ nor of $3$.] and (ii) there is overlap between these two sets.^[For instance, $6$ is a multiple of both $2$ and $3$.]

:::{#exm-simple-partitions}
## Partitions of the Coin Game
Charles and Sadie are thinking back with fondness to their original coin flipping game, where they would toss a coin three times in a row. If two or more heads showed up, Charles would pay. Otherwise, Sadie would. 

To help them reminisce, write down three different partitions of the sample space, each with a different number of partitioning sets. Describe your partitions using words.

::::{.callout .solution collapse='true'}
## Solution
There are many possible partitions to write down. The following are examples.

1. We can partition the space into games where Charles pays and games where Sadie pays. This gives \begin{align*}
B_1 &= \{(\text{H},\text{H},\text{H}), (\text{H},\text{H},\text{T}), (\text{H},\text{T},\text{H}), (\text{T},\text{H},\text{H})\}\\
B_2 &= \{(\text{T},\text{T},\text{T}), (\text{T},\text{T},\text{H}), (\text{T},\text{H},\text{T}), (\text{H},\text{T},\text{T})\}.\end{align*}

2. We can partition the space into those with $0$, $1$, $2$, or $3$ heads. This gives \begin{align*}
B_1 &= \{(\text{H},\text{H},\text{H})\}\\
B_2 &= \{(\text{T},\text{T},\text{H}), (\text{T},\text{H},\text{T}), (\text{H},\text{T},\text{T})\}\\
B_3 &= \{(\text{H},\text{H},\text{T}), (\text{H},\text{T},\text{H}), (\text{T},\text{H},\text{H})\}\\
B_4 &= \{(\text{H},\text{H},\text{H})\}.
\end{align*}

4. We can partition the space into the number of times the sequence switches between heads and tails. There will be either $0$ switches, $1$ switch, or $2$ switches. This gives \begin{align*}
B_1 &= \{(\text{H},\text{H},\text{H}), (\text{T},\text{T},\text{T})\}\\
B_2 &= \{(\text{T},\text{T},\text{H}), (\text{H},\text{T},\text{T}), (\text{H},\text{H},\text{T}), (\text{T},\text{H},\text{H})\}\\
B_3 &= \{(\text{T},\text{H},\text{T}), (\text{H},\text{T},\text{H})\}.
\end{align*}
::::
:::

Partitions allow us to move from discussions regarding the joint probability of events to the marginal probability of an event. Suppose that we have a partition given by $B_1, B_2, \dots$. This means that our full sample space can be cut up into these various non-overlapping sets, and every single outcome belongs to exactly one of them. Now, suppose we are interested in some other event $A$. We can ask: how can $A$ occur, in terms of the events $B_1, B_2, \dots$? 

Since every single event in the sample space belongs to exactly one of our partitioning sets, then it **must** be the case that every single event in $A$ belongs to exactly one of our partitioning sets. This means that if we consider $A\cap B_j$, for all $j$, then every single event in $A$ must belong to exactly one of these. In other words, it must be the case that $$A = \bigcup_{j} A\cap B_j,$$ for any partition $B_1, B_2,\dots$. Moreover, every single $A\cap B_j$ is disjoint from every other $A \cap B_\ell$, whenever $\ell \neq j$. This means that we can use the axiom of additivity to give $$P(A) = P\left(\bigcup_{j} A\cap B_j\right) = \sum_{j} P(A \cap B_j).$$ In other words: the marginal probability of $A$ can be found by summing over **all** joint probabilities between $A$ and sets that form a partition. This argument gives the law of total probability.

![This graphic shows the argument that summing over the joint probabilities between an event and a partition gives the full marginal probability. Note that $B_1,\dots,B_7$ forms a partition of the space where every possible outcome is contained in exactly one of these sets. Then, if we take an arbitrary event $A$, we can divide $A$ into the components that intersect with each partitioning set, namely $A \cap B_1$, $A \cap B_2$, and so forth.](/graphics/ch4-basic-partition){#fig-basic-partition}

:::{.callout-tip icon="false"}
## The Law of Total Probability
Given a partition, $B_1, B_2, \dots$, and an event $A$, the law of total probability states that $$P(A) = \sum_i P(A, B_i) = \sum_i P(A|B_i)P(B_i).$$
:::

Intuitively, since the whole sample space is divided into the different $B_i$s, this rule breaks down the calculation of $A$ happening into manageable chunks. Each term in the summation is "the probability that $A$ happens, given $B_i$ happening" weighted by how likely it is that $B_i$ happens. Then by summing over all possible $B_i$, we know that we must be capturing all possible ways that $A$ can occur since all parts of the sample space are contained in exactly one of the sets of our partition. The law of total probability is an indispensable tool for computing probabilities in practice. 

:::{#exm-lotp-example}
## Sadie's Possibly Late Package
Sadie has still not received the package that Charles had ordered. While it is not late yet, Charles decides to figure out the probability that the package will end up being late. Recall that company $A$ is late $75\%$ of the time while company $B$ is late $15\%$ of the time, and the store that Charles ordered from sends out $10\%$ of packages with company $A$, and the rest with company $B$, which is more likely. 

What is the probability that the package arrives late?

::::{.callout .solution collapse='true'}
## Solution
Note that $A, B$ forms a partition of the sample space as every package is either sent with $A$ or with $B$, and no package can be sent with both. Further, if $L$ represents the event that the package is late, then we know that $P(L|A) = 0.75$ and $P(L|B) = 0.15$. Since $P(A) = 0.1$ and $P(B) = 0.9$, an application of the law of total probability gives $$P(L) = P(L|A)P(A) + P(L|B)P(B) = (0.75)(0.1) + (0.15)(0.9) = 0.21.$$ As a result, knowing nothing else, the package has a probability of $0.21$ of being late.
::::
:::

:::{#exm-lotp-example-two}
## Charles' Many Urns
While shopping at some garage sales one Sunday morning, Charles and Sadie stumble across a wonderful find! They see three urns which are **exactly** identical to the one that Charles had already purchased to store the different balls which turned out to not be balls at all. Realizing the opportunity they splurge and purchase them all, and then divide the various objects between the four urns, placing all the spheres in one container, all the cubes in another, all the pyramids in a third, and all the cones in a fourth.

Once done, they use a different selection mechanism. First, they pick an urn at random. Next, they randomly grab one of the items from within it. The distribution of colours and shapes is included in the following table.

| **Colour** | **Sphere (Urn 1)** | **Cube (Urn 2)** | **Pyramid (Urn 3)** | **Cone (Urn 4)** |
|-|:--:|:--:|:--:|:--:|
| **Red**    | 2          | 3        | 2           | 0        |
| **Blue**   | 1          | 0        | 0           | 6        |
| **Green**  | 2          | 2        | 1           | 2        |
| **Yellow** | 0          | 4        | 2           | 1        |
| **Black**  | 3          | 1        | 1           | 2        |


a. What is the probability that they select any of the five colours under this sampling scheme? 
b. How does this change if the probability that each urn is selected is proportional to the number of items in it? (Thus, urn 1 is selected with probability $8/35$, and so forth).

::::{.callout .solution collapse='true'}
## Solution
a.  Let $R$, $B$, $G$, $Y$, and $Bk$ be the events that a red, blue, green, yellow, or black ball are selected. Further, let $U_1$, $U_2$, $U_3$, and $U_4$ be the events that the first, second, third, or fourth urn are selected. Then note that, according to the law of total probability, $$P(R) = P(R, U_1) + P(R, U_2) + P(R, U_3) + P(R, U_4) = \sum_{j=1}^4 P(R|U_j)P(U_j).$$ An equivalent argument holds for each of the other colours. Now, $$P(R|U_j) = \dfrac{N_{R\cap U_j}}{N_{U_j}},$$ where $N_{R\cap U_j}$ is the number of red objects in urn $j$ and $N_{U_j}$ is the total number in urn $j$. Plugging this in and simplifying we get $$P(R) = \sum_{j=1}^4P(R|U_j)\left(\dfrac{1}{4}\right) = \dfrac{1}{4}\left\{\dfrac{2}{8} + \dfrac{3}{10} + \dfrac{2}{6}\right\} = \dfrac{53}{240}.$$

    We can apply analogous arguments to the other colours giving \begin{align*}
P(B) &= \dfrac{1}{4}\left\{\dfrac{1}{8} + \dfrac{6}{11}\right\} = \dfrac{59}{352} \\
P(G) &= \dfrac{1}{4}\left\{\dfrac{2}{8} + \dfrac{2}{10} + \dfrac{1}{6} + \dfrac{2}{11}\right\} = \dfrac{527}{2640}\\
P(Y) &= \dfrac{1}{4}\left\{\dfrac{4}{10} + \dfrac{2}{6} + \dfrac{1}{11}\right\} = \dfrac{34}{165}\\
P(Bk) &= \dfrac{1}{4}\left\{\dfrac{3}{8} + \dfrac{1}{10} + \dfrac{1}{6} + \dfrac{2}{11}\right\} = \dfrac{1087}{5280}.
\end{align*}

    Note that these probabilities sum to $1$. In decimal these simplify to approximately `r paste0(round(c(53/240, 59/352, 527/2640, 34/165, 1087/5280), 3), collapse = ", ")`.

b.  Using the same setup as before, we have $$P(R) = P(R, U_1) + P(R, U_2) + P(R, U_3) + P(R, U_4) = \sum_{j=1}^4 P(R|U_j)P(U_j).$$ Now $P(U_1) = 8/35$, $P(U_2) = 10/35$, $P(U_3) = 6/35$, and $P(U_4) = 11/35$. Moreover, the conditional probabilities themselves do not change, and so instead we have $$P(R) = \left\{\dfrac{2}{8}\cdot\dfrac{8}{35} + \dfrac{3}{10}\cdot\dfrac{10}{35} + \dfrac{2}{6}\dfrac{6}{35} + \dfrac{0}{11}\cdot\dfrac{11}{35}\right\} = \dfrac{N_R}{35}.$$ Note that when multiplying by the marginal probability of the urn, the denominator will always cancel. As a result, we end up with the total number of reds over $35$, which leads to $P(R) = \dfrac{1}{5}$. The same will be true for the other colours, and as a result, if we choose the urn based on a weighted selection, this will result in equal probability once more.
::::
:::

### Bayes' Theorem
We have seen the direct computation of marginal probabilities (while using an equally likely outcome model), the computation of conditional probabilities, the use of the multiplication rule for joint probabilities, and the use of the law of total probability to indirectly calculate marginal probabilities through conditioning arguments. Throughout these discussions we have been primarily concerned with keeping events $A$ and $B$ arbitrary. Everything that we have indicated for $P(A)$ holds for $P(B)$, as does $P(A|B)$ and $P(B|A)$. In reality, it will often be the case that conditioning on one of the events will be natural, while conditioning on the other will be more tricky. In these events, it can be useful to be able to transform statements regarding $P(A|B)$ into statements regarding $P(B|A)$, and vice versa.

Note that because the definitions are symmetric, $$P(A|B)P(B) = P(A,B) = P(B|A)P(A).$$ This is an application of the multiplication rule in two different orientations. If we divide both sides of the equality by $P(B)$, assuming that it is not $0$, then we get $$P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}.$$ Now, if we form a partition, say $A,A_2,A_3,\dots$, then we can rewrite $P(B)$ using the law of total probability as $$P(B) = P(B|A)P(A) + P(B|A_2)P(A_2) + \cdots = P(B|A)P(A) + \sum_{i=2}P(B|A_i)P(A_i).$$ Taken together this gives a result known as Bayes' Theorem.^[Bayes' Theorem is named in the same way that the Bayesian interpretation of probability is, and that Bayesian statistics is more broadly. The connections are more than merely surface: Bayes' Theorem can be viewed as the primary technique with which we can update subjective beliefs about the world. Importantly, however, even those who use a Frequentist view of statistics accept the math of Bayes' Theorem, and use it frequently.]

:::{.callout-tip icon='false'}
## Bayes' Theorem
Suppose that there are two events, $A$ and $B$, with $P(B) > 0$. Moreover, suppose that $A$ taken with $A_2, A_3, \dots$ forms a partition. Then Bayes' Theorem states that $$P(A|B) = \dfrac{P(B|A)P(A)}{P(B)} = \dfrac{P(B|A)P(A)}{P(B|A)P(A) + \sum_{i=2} P(B|A_i)P(A_i)}.$$
:::

Bayes' Theorem allows us to convert statements regarding $P(B|A)$ into statements regarding $P(A|B)$. Note that, as we derived above, Bayes' Theorem is an application of the multiplication rule and an application of the law of total probability.^[In fact, I would go as far as to suggest that learning Bayes' Theorem by itself is less important than fully grasping the definition of conditional probability alongside the multiplication rule and the law of total probability. I myself do not remember Bayes' Theorem directly, but can write it down directly from these definitions without any thought.] Sometimes we may have $P(B)$ directly, rendering the law of total probability in the denominator unnecessary. 

Often, the natural partition to select when we do need the law of total probability is to take $A$ and $A^C$. Note that any set with its complement forms a partition, since by definition they occupy the entire space and are non-overlapping. When this is done we get the slightly more compact relationship of $$P(A|B) = \dfrac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)}.$$

Bayes' Theorem differs from our previous relationships as it allows us to translate one set of conditional probabilities into another. Every other relationship we have looked at has moved between types of probabilities, whereas Bayes' Theorem deals directly with conditional relationships. 

A commonly used example application for Bayes' Theorem is medical testing. Suppose that we know the performance characteristics of a particular medical test: it is $99\%$ accurate for positive cases, and $95\%$ accurate for negative cases. That is, with probability $0.99$ it correctly returns positive when an individual is infected, and with probability $0.95$ it returns negative when an individual is not infected. These are both statements of conditional probability. 

If we take $A$ to be the event that the test returns positive, and $B$ to be the event that the patient is infected,^[It is worth drawing attention to the language that we have started to use at this point in the notes regarding "events". In this case our sample space would actually be formed using pairs of information. In particular, we might have $$\mathcal{S} = \{(\text{Pos. Test}, \text{Illness}), (\text{Neg. Test}, \text{Illness}),(\text{Pos. Test}, \text{No Illness}),(\text{Neg. Test}, \text{No Illness})\}.$$ Then the event $A$ here is actually $A = \{(\text{Pos. Test}, \text{Illness}),(\text{Pos. Test}, \text{No Illness})\}$ and $B$ is $\{(\text{Pos. Test}, \text{Illness}),(\text{Neg. Test}, \text{Illness})\}$. It is far more clunky to make explicit these events, and so we move towards using more natural language. Until you feel confident that you can identify the specific outcomes associated with the events of interest, it is worth writing these out in full.] then we are saying that $P(A|B) = 0.99$ and $P(A^C|B^C) = 0.95$ which means that $P(A|B^C) = 0.05$.^[Since $P(A|B^C) = 1 - P(A^C|B^C) = 1 - 0.95 = 0.05$.] Suppose that we know that, across the entire population, one in a thousand individuals is likely to be infected. This means that $P(B) = 0.001$. 

Now if a random individual goes into a doctor's office and tests positive for the disease, how likely are they to actually be infected? In this case we want to know the probability of them being infected given that they have tested positive. In notation, this is $P(B|A)$. We do not know this quantity directly, but given an application of Bayes' Theorem, we can find it. Using the natural partition of $B$ and $B^C$, we get $$P(B|A) = \dfrac{P(A|B)P(A)}{P(A|B)P(B)+P(A|B^C)P(B^C)} = \dfrac{(0.99)(0.001)}{(0.99)(0.001)+(0.05)(0.999)} \approx 0.019.$$ That is, despite the fact that this test is exceptionally effective at detecting this disease, a positive test still means that an individual has a probability of only $0.019$ of actually having the illness.^[This counterintuitive fact was an intensely frustrating reality for statisticians everywhere during the height of the COVID-19 pandemic, when politicians and the population at large turned away from testing owing to its perceived "ineffectiveness". The quantity of interest for knowing how good a test is, is $P(A|B)$ and $P(A^C|B^C)$. However, if a disease is sufficiently rare, with $P(B)$ sufficiently small, then no matter how effective the tests are you will likely have $P(B|A)$ to be low. Note that $P(B|A) >> P(B)$ in the example, and this will also be true in general. A single test cannot say with certainty, however, they are an incredibly effective tool at reducing our uncertainty.]

:::{#exm-bayes-theorem}
## Sadie's Late Package
Sadie eventually received the package that Charles had sent, but it arrived very late. Sadie was not home when the package was delivered and there no obvious markings on the box to indicate which of the two delivery companies had sent it. 

Given this information, and knowing that company $A$ is late $75\%$ of the time while company $B$ is late $15\%$ of the time, and the store that Charles ordered from sends out $10\%$ of packages with company $A$, and the rest with company $B$, what is the probability that the package was delivered by each of the two companies?

::::{.callout .solution collapse='true'}
## Solution
We want to determine $P(A|L)$ and $P(B|L)$. We know that $P(L|A) = 0.75$ and $P(L|B) = 0.15$. Moreover, we know that $P(A) = 0.1$ and $P(B) = 0.9$. Applying Bayes' Theorem directly we get $$P(A|L) = \dfrac{P(L|A)P(A)}{P(L|A)P(A) + P(L|B)P(B)} = \dfrac{(0.75)(0.10)}{(0.75)(0.10) + (.10)(0.90)} = \dfrac{5}{11}.$$ Similarly, we get $$P(B|L) = \dfrac{P(B|A)P(B)}{P(L|A)P(A) + P(L|B)P(B)} = \dfrac{(0.15)(0.90)}{(0.75)(0.10) + (.10)(0.90)} = \dfrac{6}{11}.$$ Note, we could have also used the fact that $P(A|L) + P(B|L) = 1$ to determine this. As a result, it is more likely that $B$ delivered the package than $A$.^[Note that this is another example of a counterintuitive result. Here, $A$ is far more likely to be late, but it is more likely that $B$ delivered a late package to us than $A$ because of the **base rates**. That is, $P(B)$ is much higher to begin than $P(A)$, and so that is hard to overcome. It is worth noting, however, that originally $P(B)$ is $9$ times more likely than $P(A)$, and after knowing that package is late it is $\dfrac{6}{5} = 1.2$ times more likely. This major reduction in the relative likelihood is owed to how much more likely $A$ is to deliver late packages than $B$.]
::::
:::

Bayes' Theorem highlights a key lesson when considering conditional probabilities, and it's a common mistake to make which should be avoided at all costs. Namely, we cannot interchange $P(A|B)$ with $P(B|A)$. These probabilities are not necessarily highly correlated with one another, and it is important to distinguish clearly which is the probability of interest.^[Mixing up $P(B|A)$ and $P(A|B)$ is often called *confusion of the inverse*, and it can lead to very faulty conclusions when ignored. In the medical testing example above, it is important to not confuse "the probability that the test returns positive, assuming you have the illness" with "the probability that you have the illness, given that the test returns positive." This type of faulty logic has long been used to justify discriminatory behaviour in medicine, the law, and so on. A thorough understanding of statistics and probability helps to ensure that these types of errors are not made, and gives you the tools to push-back on the spots where people are making these arguments incorrectly, particularly when the stakes are high or harm is being done.] The stakes of these types of confusion can be quite high, and it is tremendously important to ensure that you are conditioning on the correct events. Fortunately, Bayes' Theorem allows us to translate between events for conditioning, giving a mechanism from translating between the two.^[When discussing Bayes' Theorem we introduced two frequently occurring sources of error when reasoning about probabilities, and showed how to remedy them. *Confusion of the inverse* occurs when you mix up $P(A|B)$ with $P(B|A)$, and can lead to disastrous consequences. The *base rate fallacy* occurs when you fail to take into account the rareness of the marginal events and instead only consider the conditionals (such as seeing that delivery company $A$ was more likely to be late than $B$, without considering that $B$ was more likely to be used than $A$). These are both examples of the challenges at the heart of probability and statistics: namely, the subjects are fairly unintuitive once moving beyond the basics. As a result, we need to rely on building up our intuitions over time by making use of the formal rules that we are able to derive.]

## Independence
We have seen that, in most cases, conditioning on an event changes the probability of that event. For instance, if we want to know the probability it is raining, if we condition on knowing that it is a day full of gray skies, the conditional probability is likely higher than the marginal probability. By considering how the marginal and conditional probabilities differ, we are in effect indicating a dependence of the events on one another. In terms of probability, this dependence is captured by an influence on the degree of uncertainty present depending on what we know.

It is totally possible that two events do not influence one another at all. The weather outside today is likely not influenced by your favourite sports team's performance last night.^[Though, perhaps the world will freeze over if *(insert-your-least-favourite-team-here)* wins the *(insert-the-name-of-the-championship-for-the-league-you-care-about-here)*?] In this case, we would have $P(A|B) = P(A)$. 

We saw an example of this previously when we wanted to know the probability of a randomly selected card being a heart ($A$) given that it was an ace ($B$). We found that this was $\dfrac{1}{4}$, exactly the same as the probability if we did not know that it was an ace. Thus, here we have $P(A|B)=P(A)$. We could have also said that $P(B|A)=P(B)=\dfrac{1}{13}$. The symmetry of these events makes it somewhat more convenient to express this relationship differently. 

Instead of writing $P(A|B) = P(A)$ and $P(B|A) = P(B)$, we can multiply the first relationship by $P(B)$ on both sides, or the second by $P(A)$ on both sides. The multiplication rule gives $P(A|B)P(B) = P(A,B)$, and so the first relationship becomes $P(A,B) = P(A)P(B)$. The second follows exactly the same. Any two events that satisfy this relationship are said to be independent. 

:::{#def-independence}
## Independence
Any two events, $A$ and $B$, which satisfy $P(A,B) = P(A)P(B)$ are said to be independent. If $A$ and $B$ are independent we write $A\perp B$, and read "$A$ is independent of $B$". Any events which are not independent are said to be dependent, and we write $A\not\perp B$.
:::

Note that independence is always a symmetric property: if $A$ is independent of $B$, then $B$ is independent of $A$. To check whether two events are independent, we check whether their joint probability is equal to the product of their marginal probabilities.

:::{.callout-warning icon='false' collapse='true'}
## Properties of Independence
Note that if $A\perp B$, then $A^C\perp B$, $A^C\perp B^C$, and vice versa. To see this note $$P(A^C, B) + P(A, B) = P(B),$$ by the Law of Total Probability. Then, by independence of $A$ and $B$ this gives \begin{align*}
P(A^C, B) + P(A)P(B) &= P(B) \\
\implies P(A^C, B) &= P(B) - P(A)P(B) \\
&= P(B)(1 - P(A)) \\
&= P(B)P(A^C),\end{align*} as is required. The other combinations follow in the same manner.
:::

If $P(A)\neq 0$, then we can divide both sides by $P(A)$ to gives $P(B|A) = P(B)$. Similarly, if $P(B)\neq 0$, then we can divide both sides by $P(B)$ to give $P(A|B)=P(A)$. This expression in terms of conditional probabilities is the more intuitive expression of independence. It directly captures the idea that "knowing $B$ does not change our belief about $A$". However, we must be careful. This conditional argument is only valid when the event that is being conditioned on is not probability $0$, where the defining relationship, $P(A,B) = P(A)P(B)$, will hold for all events. Recall that, in general, $$P(A\cap B) = P(A)+P(B)-P(A\cup B).$$ It is only when assuming independence that this simplifies further. 

:::{.remark}
## The Multiplication and Addition Rules of Probability

Often, in elementary probability and statistics courses, the **Multiplication Rule** and the **Addition Rule** for calculating probabilities are emphasized and named. It is emphasized that to calculate probabilities, we will often multiply together other probabilities, or else add a sequence of them. These rules often form the backbone of probability computation. At this point, we have now seen both the typical Multiplication Rule and the typical Addition Rule, without drawing specific attention to them as such.

The multiplication rule states that, for independent events $A$ and $B$, $P(A\cap B) = P(A)P(B)$. That is, with independent events if you want to know the probability that they both happen, you multiply together the probabilities. The addition rule states that, for disjoint events $A$ and $B$, $P(A \cup B) = P(A) + P(B)$. That is, with disjoint events if you want to know the probability that either or occurs, you add them together. These can be quite handy tools when correctly applied. 

For instance, if we assume that we flip a coin then roll a die, we can say that the probability that you get a head and an even number must be $\dfrac{1}{2}\times\dfrac{1}{2} = \dfrac{1}{4}$ since $P(\text{Heads}) = \dfrac{1}{2}$ and $P(\text{Even}) = \dfrac{1}{2}$, and the coin flip must be independent of the die roll. Similarly, suppose that we wish to know what the probability that, when drawing a card from a standard deck of $52$ cards, the result is an Ace, Three, Six, or King. Here we can say that this must be $\dfrac{4}{52} + \dfrac{4}{52} + \dfrac{4}{52} + \dfrac{4}{52} = \dfrac{4}{13}$. This is because each rank has a $\dfrac{4}{52}$ chance of occurring, and each of these events are disjoint.

So, if the multiplication and addition rules are handy, why do we not discuss them directly in these notes? As pointed out, we did learn both of the rules: the multiplication rule is the defining relationship for independent events, and the addition rule is the axiom of additivity. However, highlighting these as substantially more important than the surrounding topics can lead to deeper struggles with probability calculations. Specifically, these two techniques apply in only very limited situations: if we know that events are independent, or we know that events are disjoint. Most of the time, neither assumption is going to hold, and in those settings we need to move past multiplying or adding to critically thinking about the specific quantities. This can lead to deeper confusion in translating these beyond simple examples.

The concern here moves beyond ensuring success in introductory sequences of probability and statistics. Uncritical deference to the multiplication and addition rules can have dire real-world consequences. As one particularly sobering example, [Sally Clark](https://en.wikipedia.org/wiki/Sally_Clark){target="_BLANK"} was convicted in 1999 of the murder of her two sons, each of whom had died a few weeks following their birth. The defense claimed that the deaths were the results of Sudden Infant Death Syndrome (SIDS). The prosecution presented a statistical analysis from a paediatrician, Roy Meadow, who claimed that the probability of an infant dying of SIDS is approximately $\dfrac{1}{8500}$. An application of the multiplication rule then tells us that the probability that both of Sally Clark's sons would die of SIDS is $$\dfrac{1}{8500}\times\dfrac{1}{8500} = \dfrac{1}{72,250,000}.$$ This is very rare, and seemed strong enough evidence to convict Sally Clark. The conviction was later overturned on an appeal, owing to both additional evidence coming to light and a [critique of the statistical reasoning employed in the case](https://web.archive.org/web/20110824151124/http://www.rss.org.uk/uploadedfiles/documentlibrary/744.pdf){target="_BLANK"} published by the Royal Society of Statistics, but only after Sally Clark had served more than three years of a prison sentence. 

The stakes of these types of calculations can be tremendously high, and it is critically important to not rely on simplified rules when working with probabilities and statistics. As individuals armed with the tools of probability and statistics it is imperative that we remain responsible with our application of these techniques; there is an air of authority that is carried by quantitative statements, and when misplaced, the consequences can be dire.

:::

:::{#exm-assessing-independence}
## Independence and Board Games
Charles and Sadie are invited over by their friend, Garth, to play some board games. Both of them are quite excited by this prospect! Board games feel like the next logical step for the two of them to highlight their love of both probability and games! Garth has a large board game collection, and begins to explain the games to Charles and Sadie across a variety of axes:

* Whether the games are competitive or cooperative.
* How many players the games play best at ($\{1, 2, 3, 4+\}$).
* How "heavy" the games tend to be (friendly for everyone, moderately involved, or very heavy).

While Garth continues on about several other topics including the themes, the mechanics, or the rating on BoardGameGeek, Charles drifts off wondering whether the traits listed are independent in Garth's collection. Suppose that Garth has $100$ games, of which:

* $25$ are cooperative.
* $5$ are best played at one player, $20$ at two, and $55$ at three. 
* $10$ are friendly for everyone and $45$ are moderately involved. 

a. If $5$ games are best played at two players and are cooperative, are these events independent?
b. If $20$ games are heavy and best played with $4+$ players, are these events independent?
c. If $0$ games are both moderately involved and cooperative, are these events independent?
d. Charles figures that competitive games and two player games are independent. How many competitive two player games are there?
e. Is it possible that competitive games are independent of heavy games?

::::{.callout .solution collapse='true'}
## Solution
a. We are suggesting that $P(A,B) = 0.05$, where $A$ is "two player" and $B$ is "cooperative". We know that $P(B) = 0.25$ and $P(A) = 0.20$. Calculating $P(A)P(B) = (0.20)(0.25) = 0.05 = P(A,B)$, and so these traits **are** independent.

b. We have $P(A,B) = 0.2$ where $A$ is "heavy" and $B$ is "$4+$ players". We know that $P(A) = 0.45$ and $P(B) = 0.20$, and so $P(A)P(B) = (0.45)(0.20) = 0.09 \neq P(A,B)$. As a result, these traits are **not** independent.

c. We know that $P(A) > 0$ and $P(B) > 0$ for $A$ being moderately involved and $B$ being cooperative. As a result, $P(A)P(B) > 0$, and so if $P(A,B) = 0$, they must **not** be independent. 

d. Taking $A$ to be "competitive" we have $P(A) = 0.75$. Taking $B$ to be "two player" we have $P(B) = 0.20$. As a result, if $A\perp B$ then $P(A,B) = P(A)P(B) = (0.75)(0.20) = 0.15$. Thus, there must be $15$ competitive, two player games.

e. Taking $A$ to be "competitive" we have $P(A) = 0.75$. Taking $B$ to be "heavy" we have $P(B) = 0.45$. Thus, if they were independent, we would have $P(A,B) = P(A)P(B) = (0.75)(0.45) = 0.3375$. This would require $34.75$ games to be heavy, competitive games, and so we must conclude that they are **not** independent. 

::::
:::

#### Mutually Exclusive Events
Importantly, if $A\perp B$, then $A\cap B\neq \emptyset$ unless at least one of $A$ or $B$ equals $\emptyset$ or $\mathcal{S}$. To see this recall that $P(\emptyset) = 0$, and so if $A\cap B = \emptyset$ then $P(A\cap B) = P(A)P(B) = P(\emptyset) = 0$. Moreover, $P(\mathcal{S}) = 1$ and $\mathcal{S} \cap B = B$, so $P(\mathcal{S} \cap B) = 1P(B) = P(B)$. This only holds if either probability is $0$ or $1$. This may seem to be a rather technical point, however, it is the source of much confusion regarding independence. In particular, it is common to mistake independent events for mutually exclusive events.

:::{#def-mutually-exclusive-events}
## Mutually Exclusive Events
Two events, $A$ and $B$ are said to be mutually exclusive if they are disjoint. In particular, if $P(A,B) = 0$ then $A$ and $B$ are mutually exclusive. If $A$ and $B$ are mutually exclusive events, with $P(A) > 0$ and $P(B) > 0$, then $A\not\perp B$.
:::

Whenever only one event from a set of events can happen, we refer to the events as being mutually exclusive. If one happens, we know that the others did not. Mutually exclusive events, with positive probability, are always dependent since knowing that $A$ occurs dramatically shifts our belief about $B$,$C$, and $D$.^[Namely, we know that all of the others are then impossible.]

The primary concern with mutually exclusive and independent events is a linguistic one. We often use words like independent to mean unrelated, and in a sense, mutually exclusive events are unrelated in that one has nothing to do with another. However, in statistics and probability, when we discuss independence, it is not an independence of the events themselves but rather an independence relating to our beliefs regarding the uncertainty associated with the events. In this sense, mutually exclusive events are very informative regarding the uncertainty associated with them.

:::{#exm-independence-two}
## Charles and Sadie Cooking Dinner
Suppose that Charles and Sadie always eat dinner together. It will either be the case that Charles cooks at home, that Sadie cooks at home, that the two of them order in, or that they go out to eat. If we take these to be four events, $A$, $B$, $C$, and $D$, then are any of these events independent? Mutually exclusive? Explain.

::::{.callout .solution collapse='true'}
## Solution
Assuming, as it seems reasonable given the information in the question, that only one of the possible tasks occurs for dinner in a night, then we *know* that $$P(A,B) = P(A,C) = P(A,D) = P(B,C) = P(B,D) = P(C,D) = 0.$$ As a result, all of the events described are mutually exclusive, and correspondingly, are *not* independent.
::::
:::

## Contingency Tables{#sec-contingency-tables}
Through to this point we have discussed probabilities in the abstract, either through an enumeration of equally likely outcomes, or else by directly specifying the likelihood of various events. While these are useful in many regards, we are often looking for more concise manners of summarizing information of interest. One tool for accomplishing this is a contingency table. 

:::{#def-contingency-table}
## Contingency Table
A contingency table is a tabular summary of information which summarizes the joint probabilities of two or more variables. Typically a contingency table will take one factor for the columns and a secondary factor for the rows, where each cell then represents the frequency with which observations occur in the two corresponding categories simultaneously.
:::

To begin, you could imagine constructing a frequency table relaying the frequency with which undergraduate students are enrolled in various faculties at a particular university. This tells you, of the whole population of students at the university, what is the faculty breakdown. By dividing the number in each faculty by the total number of students, you convert the frequencies to proportions, and these proportions can be viewed as probabilities. (See @tbl-uni-frequency.^[Note, the values in this table are *roughly* inspired by a subset of the [Fall 2022 University of New Brunswick Enrolment Numbers](https://web.archive.org/web/20240103124753/https://www.unb.ca/finance/_assets/documents/rpb/factbooktables/2022enrollment/20221215-tablee3-enrolment-ftehc-fac-acad-lvl-2022fa-final.pdf).]) The interpretation of proportions as probabilities implies a very specific statistical experiment. In particular, the proportion represents the probability that an individual selected at random from the entire population has the given trait. This is frequently a probability of interest, which makes these summary tables a useful tool.^[This provides further emphasis for the utility of urn models. If you imagine an urn that has balls with two or more traits (say like those in @exm-conditional-probability-urn), then randomly selecting a single ball from this population has an analogous probability distribution.]

```{r}
#| echo: false
#| label: tbl-uni-frequency
#| tbl-cap: "Frequency and corresponding proportions of enrolment by faculty in a university."
#| tbl-colwidths: [20,40,40]

library(knitr)
library(kableExtra)

faculties <- c("Arts", "Computer Science", "Education", "Engineering", "Law", "Nursing", "Science", "Total")
counts <- c(1266, 749, 786, 1315, 266, 543, 876)
total <- sum(counts)
counts <- c(counts, total)
props <- counts / total
kable(data.frame(Faculty = faculties, Enrolment = counts, Proportion = props)) %>%
    column_spec(1, bold = TRUE) %>% 
    row_spec(7, hline_after = TRUE, extra_css = "border-bottom: 1px solid") %>% 
    row_spec(8, bold = TRUE) 

```

When a single trait is displayed we refer to these tabular summaries as frequency tables or frequency distributions. A contingency table instead plots two or more traits on the same table, with each cell representing the frequency of both traits occurring simultaneously in the population. Extending the university example, we may further include the student's current year of study to see the breakdown of both faculty and year of study, in one table.

```{r}
#| echo: false
#| label: tbl-uni-contingency
#| tbl-cap: "Frequency of enrolment by faculty and year of study in a university."
#| tbl-colwidths: [20,40,40]

library(knitr)
library(kableExtra)

set.seed(315)

faculties <- c("Arts", "Comp. Sci.", "Education", "Engineering", "Law", "Nursing", "Science")
counts <- c(1266, 749, 786, 1315, 266, 543, 876)

count_break_down <- matrix(nrow = length(counts), ncol = 5)

for(ii in 1:length(counts)) {
    break_down <- runif(5, 0.1, 0.3)
    break_down <- break_down/sum(break_down)
    my_counts <- round(break_down * counts[ii], 0)
    my_counts[5] <- my_counts[5] + (counts[ii] - sum(my_counts))
    count_break_down[ii, ] <- my_counts
}

rownames(count_break_down) <- faculties
colnames(count_break_down) <- c("Year 1", "Year 2", "Year 3", "Year 4", "Year 5+")

# tab1 <- prop.table(count_break_down)
tab1 <- count_break_down
tab1 <- cbind(tab1, rowSums(tab1))
tab1 <- rbind(tab1, colSums(tab1))

kable(tab1, align=rep('c', 7))  %>%
    column_spec(1, bold = TRUE) %>%
    column_spec(7, bold = TRUE) %>%
    row_spec(8, bold = TRUE) %>% 
    row_spec(7, hline_after = TRUE)
```

By including two (or more) factors in the table we are able to capture not only the marginal probabilities for the population, but also the joint probabilities for the population, and in turn, the conditional probabilities for the population. Being able to concisely summarize all of these concepts regarding traits in a population of interest renders contingency tables immensely useful in the study of uncertainty broadly.

Consider the two-way contingency table, @tbl-uni-contingency. Each cell consists of frequency with which a combination of the two traits occurs in the population.^[That is, the number of students who are enrolled in that faculty, in that year of study.] If we take events corresponding to each of the levels of the two variables of interest, then these central cells represent the frequency of joint events. That is, each interior cell gives the total number of observations with a set level for variable one^[Faculty.] AND a set level for variable two^[Year of study.]. For instance, there are `r tab1[5, 2]` individuals who are in `r rownames(tab1)[5]` and studying in `r colnames(tab1)[2]`. 

Each row is then summed, with the total number following into the corresponding row recorded in the right-hand margin. Each column is summed, with the total number corresponding to the given column recorded in the bottom margin. For instance there are a total of `r tab1[3,6]` students in `r rownames(tab1)[3]` and a total of `r tab1[8,3]` in `r colnames(tab1)[3]`. Then the margin totals are summed, and the total is recorded in the lower right margin space (in this case, `r tab1[8,6]`). Whether the rows or columns are summed, they should sum to the same total, which is the total of the population under consideration. This is the same as simply adding all the observed interior frequencies. To turn a frequency into a probability, you need only divide the correct frequency by the correct total.

```{r}
#| echo: false
#| label: tbl-uni-prop
#| tbl-cap: "Proportions of enrolment by faculty and year of study in a university."
#| tbl-colwidths: [20,40,40]

library(knitr)
library(kableExtra)

# tab1 <- prop.table(count_break_down)
tab2 <- prop.table(count_break_down)
tab2 <- cbind(tab2, rowSums(tab2))
tab2 <- rbind(tab2, colSums(tab2))

kable(tab2, align=rep('c', 7))  %>%
    column_spec(1, bold = TRUE) %>%
    column_spec(7, bold = TRUE) %>%
    row_spec(8, bold = TRUE) %>% 
    row_spec(7, hline_after = TRUE)
```

For the standard joint probabilities, you take the interior cell count and divide by the population total. Here we are saying that some fixed number, $m$, of the $N$ total individuals have both traits under consideration. For instance, the joint probability that a student is in `r rownames(tab2)[5]` and studying in `r colnames(tab2)[2]` is `r tab2[5, 2]`.^[It is worth reemphasizing what this probability actually means. If we were to randomly sample, with equal probability, individuals from this population then the probability that an individual selected has both the faculty and year specified is given by the joint probability. That is to say, if we did this over and over and over again (with replacement) in the long-term, these probabilities represent proportion of time those combinations would be observed.] If instead you wish to find a marginal probability, you have to consider the value in the corresponding margin: this is the total number of individuals with the given trait, ignoring the level of the other variable. These marginal values are also divided by the total population size. For instance, there is a `r tab2[3,6]` probability of observing a student in `r rownames(tab2)[3]` and a probability `r tab2[8,3]` of observing a student in `r colnames(tab2)[3]`.

Outside of joint and marginal probabilities, we can also find conditional probabilities. To do so, we restrict our focus to either only one row, or one column. Then, we can take the joint cell and divide by the value in the margin, which gives the conditional probability of interest. Note, this works with *either* the contingency table directly **or** with the propensity table. The reasoning is that the propensity table divided by the same totals in the numerator and the denominator. Suppose we take some cell, $A\cap B$, which has $N_{A, B}$ in the contingency table. Then, $$P(A\cap B) = \dfrac{N_{A, B}}{N} \quad\quad\text{and}\quad\quad P(B) = \dfrac{N_B}{N}.$$ If we consider then forming $P(A|B)$ we get $$P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{N_{A \cap B}/\cancel{N}}{N_B/\cancel{N}} = \dfrac{N_{A, B}}{N_B}.$$ Thus, given that we know a student is in `r rownames(tab2)[3]`, then the probability that they are in `r colnames(tab2)[3]` is approximately `r round(tab2[3,3]/tab2[3,6],5)`.

Note that these procedures are exactly in line with what we had seen before. The conditional probability is defined as the joint probability divided by the marginal probability. The process of computing the marginal can be seen as an application of the law of total probability. As a result, contingency tables can be a useful, tangible tool for investigating the techniques we have been discussing: they are not a substitute for direct manipulation of the mathematical objects, but they can present insight into the underlying processes where it may be hard to derive that insight otherwise.

:::{.callout-warning collapse="true" icon="false"}
## The Law of Total Probability: Contingency Table's Version
Recall that the law of total probability states that, if $B_1,\dots,B_n$ forms a partition of the sample space, then $$P(A) = \sum_{i=1}^n P(A|B_i)P(B_i) = \sum_{i=1}^n P(A, B_i)$$. In a contingency table it is easier to see how either of the two factors at play (either those in the rows or the columns) forms a partition of the space. Every observation has to fall in exactly one row and exactly one column. Thus, if we want to know the marginal frequency of a single trait (say represented by some row of the table), then one way to find this total is to sum up every observation in each of the corresponding columns. This is *precisely* the same process as the law of total probability. Note that, denoting each column as $B_i$, and supposing there are $k$ total columns, then the total number in a row is taken to be $$N_A = \sum_{i=1}^k N_{A, B_i},$$ simply as the summation of the corresponding row. By definition, $P(A) = \dfrac{N_A}{N}$, and so dividing both sides by $N$ gives $$P(A) = \dfrac{N_A}{N} = \dfrac{1}{N}\sum_{i=1}^k N_{A, B_i} = \sum_{i=1}^k \dfrac{N_{A, B_i}}{N} = \sum_{i=1}^n P(A\cap B_i).$$
:::

It is important to note that there is redundant information within a contingency table. For instance, the margins need not be listed explicitly, as they can be directly calculated from the interior points. The same goes for interior points, given the margins of the table (assuming *some* interior points are also presented). This can be useful for a compact representation of the information, and manipulating these tables -- being able to find the required information in many places -- should become familiar to you as you continue to work with them more and more.

:::{#exm-charles-contingency-table}
## The Evolving Contents of Charles' Urns
After learning of contingency tables, Sadie points out to Charles that with the whole urn debacle they went through, the two of them actually ended up using a contingency table to summarize the information. How neat! In the interim, there has been some development in the contents of Charles's urns, and armed with the new knowledge of contingency tables, the following summary is produced. 
```{r}
#| echo: false

library(knitr)
library(kableExtra)

set.seed(314)

shapes <- c("Sphere", "Cube", "Pyramid", "Cone")
colours <- c("Red", "Blue", "Green", "Yellow", "Black")

all_shapes <- sample(shapes, 50, TRUE)
all_colours <- sample(colours, 50, TRUE)

charles_data <- data.frame("Colours" = all_colours, "Shapes" = all_shapes)

## Form a Contingency Table
charles_table <- table(charles_data)
charles_table <- cbind(charles_table, rowSums(charles_table))
charles_table <- rbind(charles_table, colSums(charles_table))

# Render the Table to be a Character Vector
charles_table[1, 2] <- "A"
charles_table[3, 3] <- "B"
charles_table[4, 2] <- "C"
charles_table[4, 5] <- "D"
charles_table[6, 2] <- "E"

kable(charles_table, align = rep("c",5))  %>%
    column_spec(1, bold = TRUE) %>%
    column_spec(6, bold = TRUE) %>%
    row_spec(6, bold = TRUE)
```
Sadly, Charles does not have the best writing and Sadie cannot make out what values were written in for the cells marked $A$, $B$, $C$, $D$, and $E$. 

a. What are the values for the missing values?
b. What is the probability that a black cube is drawn?
c. What is the probability that a red object is drawn?
d. What is the probability that a cube is drawn?
e. Given that the drawn object was a pyramid, what is the probability that it is green?
f. Given that the object is green, what is the probability that it is a pyramid. 

::::{.callout .solution collapse='true'}
## Solution
a. We start by filling in the missing cells, in order.
    i. For $A$ we can note that $2 + A + 1 + 3 = 10$, which gives that $A = 4$. We could have also tried a column sum, however, this would involve $3$ unknowns and so would not have given a numeric result.

    ii. For $B$ either a row sum or column sum would produce the correct answer. We either take $3 + 3 + B + 5 = 15$ giving $B = 4$ or $1 + 1 + B + 3 + 4 = 13$ giving $B=4$. 

    iii. $C$ is more challenging as we either have that $2 + C + 3 + 2 = D$ or $4 + 2 + 3 + C + 3 = E$^[Note here, $A=4$ has been filled in.] As a result, for this technique we will need to find either $D$ or $E$ first. There is an alternative technique to use, which would be to note that we have *all* the internal points specified at this point, and we know that these sum to $50$. As a result, we could note that $C = 50 - 10 - 5 - 15 - 13 - 2 - 3 - 2 = 0$ or that $C =  50 - 13 - 13 - 12 - 4 - 2 - 3 - 3 = 0$. 

    iv. We can find $D$ either by subtracting from the total, $D = 50 - 10 - 5 - 15 - 13 = 7$, or by adding along the row, $2 + 0 + 3 + 2 = 7$.^[We have filled in $C = 0$ here.] Note that with $D = 7$, had we not found $C = 0$ above, we could now take $2 + C + 3 + 2 = 7$ and find $C = 0$.

    v. Like $D$, we have two options for working this out. Either $E = 50 - 13 - 13 - 12 = 12$ or $E = 4 + 2 + 3 + 0 + 3 = 12$.^[This uses $A=4$ and $C=0$.] Like with $D$, had we solved for $E$ first, then we could find $C$ via $4 + 2 + 3 + C + 3 = 12$.

b. Here we want $P(\text{Black}, \text{Cube})$. This is given by the frequency of black cubes divided by $50$. Thus, $$P(\text{Black}, \text{Cube}) = \dfrac{A}{50} = \dfrac{4}{50} = 0.08.$$

c. Here we want $P(\text{Red})$. This is given by the marginal frequency of red objects divided by $50$. Thus, $$P(\text{Red}) = \dfrac{D}{50} = \dfrac{7}{50} = 0.14.$$

d.  Here we want $P(\text{Cube})$. This is given by the marginal frequency of cubes divided by $50$. Thus, $$P(\text{Cube}) = \dfrac{E}{50} = \dfrac{12}{50} = 0.24.$$

e. Here we want $P(\text{Green}|\text{Pyramid})$. This is given by the frequency of green pyramids divided by the marginal frequency of pyramids. Thus $$P(\text{Green}|\text{Pyramid}) = \dfrac{B}{13} = \dfrac{4}{13} \approx 0.308.$$ 

f. Here we want $P(\text{Pyramid}|\text{Green})$. This is given by the frequency of green pyramids divided by the marginal frequency of green objects.^[Note, we could also apply Bayes' Theorem to find the result here. We know that $P(\text{Green}|\text{Pyramid}) = 4/13$, that $P(\text{Green}) = 15/50$ and that $P(\text{Pyramid}) = 13/50$. Thus, Bayes' Theorem gives $$P(\text{Pyramid}|\text{Green}) = \dfrac{(4/13)(13/50)}{15/50} = \dfrac{4}{15},$$ exactly as in the direct derivation.] Thus $$P(\text{Pyramid}|\text{Green}) = \dfrac{B}{15} = \dfrac{4}{15} \approx 0.267.$$

::::
:::

It is also important to recognize that independence and mutually exclusive events can be codified via the table as well. Zeros on the interior points indicate events which are mutually exclusive: if we know that one of them occurred, we also know that the other one did not. For independence, it requires a degree of solving proportions. We can either check that the joint probability ($N_{A,B}/N$) is equal to the product of the two marginal probabilities, ($N_AN_B/N^2$), or else (assuming that the events are all non-zero), that the conditional probability ($N_{A,B}/N_A$) equals the marginal probability $N_B/N$. Either way this is represented by $N\times N_{A,B} = N_AN_B$, and when this holds, we can conclude that the events are independent.

:::{#exm-contingency-table-mututally-exclusive}
## Independent or Mutually Exclusive Urn Shapes
After helping Charles *neatly* fill in the contingency table, Sadie begins to wonder about whether there are any shape-colour combinations which are independent, or if any are mutually exclusive. 

```{r}
#| echo: false
charles_table <- table(charles_data)
charles_table <- cbind(charles_table, rowSums(charles_table))
charles_table <- rbind(charles_table, colSums(charles_table))

kable(charles_table, align = rep("c",5))  %>%
    column_spec(1, bold = TRUE) %>%
    column_spec(6, bold = TRUE) %>%
    row_spec(6, bold = TRUE)
```

a. Are there any events represented in the contingency table which are mutually exclusive?
b. Are there any events represented in the contingency table which are independent?

::::{.callout .solution collapse='true'}
## Solution
a. Mutually exclusive events are codified via a $0$ frequency. We can see then that $\text{Cube}$ and $\text{Red}$ are mutually exclusive. That is, if we know that an object is red, we also know that it is not a cube. And if we know that an object is a cube, then we know that it is not red.

b. Independence is more cumbersome to check. We require the product of marginal counts to be equal to the total times by the joint counts. As a result, the easiest way to check is to consider the product of each marginal value in the columns by each marginal value in the row, divided by $50$. If this value corresponds to the value in that row/column pairing, then we know that those features are independent. Note that immediately we can rule out any products which are not divisible by $50$, since we know that $N_{A,B}$ is an integer for all $A,B$ and $N_{A,B} = N_AN_B/50$ if there is independence. To this end, we only need to check the product of each of the row totals with each of $12$ and $13$ (as those are the only two unique column totals). This gives, in order $120$, $130$, $60$, $65$, $180$, $195$, $84$, $91$, $156$, and $169$. None of these values are divisible by $50$ and as a result we know that there is **no independence** codified in this table.
::::
:::

#### Contingency Tables and Data Frames in R
In R, we can use the `table` and `prop.table` to calculate the (interior) of a contingency table. This will return a `table` type object in R, which can be thought of as a matrix of sorts. On it, we can use the functions `rowSums` and `colSums` to get the summation of the rows and columns, respectively. Typically, the object we pass to `table` will be a **data frame**. A data frame is another R object type that we have not yet seen. The idea with a data frame is that we have multiple columns with different variables (of possibly different types) represented. Each row corresponds to a single observation, and then each column is read as a feature of those observations. Data frames are essentially large spreadsheets (or data tables) which indicate the various observations that we have. In practice, data frames are the most commonly used object in an R analysis, and we will see them plenty going forward.

::: {.content-visible when-format='pdf'}
```{r}
# As always, when randomization is to be used, we call
# the set.seed function to ensure that the analysis can be
# replicated.
set.seed(314)

# Begin by Defining the possible shapes and colours for
# the objects in Charles's urns
shapes <- c("Sphere", "Cube", "Pyramid", "Cone")
colours <- c("Red", "Blue", "Green", "Yellow", "Black")

# Use sample to draw 50 different shapes, and 50 different
# colours. We are drawing *with* replacement.
all_shapes <- sample(x = shapes, size = 50, replace = TRUE)
all_colours <- sample(x = colours, size = 50, replace = TRUE)

# Now we form the data frame. This will consist of two columns,
# one called "Colours" and one called "Shapes". The values to 
# place here will correspond to the random colours and shapes we
# sampled above.
charles_data <- data.frame("Colours" = all_colours, "Shapes" = all_shapes)

# To get a sense of the data frame we can use the head function
# which will return the first few rows of our data frame.
head(charles_data)
```
:::
::: {.content-visible when-format='html'}
```{webr-r}
# As always, when randomization is to be used, we call
# the set.seed function to ensure that the analysis can be
# replicated.
set.seed(314)

# Begin by Defining the possible shapes and colours for
# the objects in Charles's urns
shapes <- c("Sphere", "Cube", "Pyramid", "Cone")
colours <- c("Red", "Blue", "Green", "Yellow", "Black")

# Use sample to draw 50 different shapes, and 50 different
# colours. We are drawing *with* replacement.
all_shapes <- sample(x = shapes, size = 50, replace = TRUE)
all_colours <- sample(x = colours, size = 50, replace = TRUE)

# Now we form the data frame. This will consist of two columns,
# one called "Colours" and one called "Shapes". The values to 
# place here will correspond to the random colours and shapes we
# sampled above.
charles_data <- data.frame("Colours" = all_colours, "Shapes" = all_shapes)

# To get a sense of the data frame we can use the head function
# which will return the first few rows of our data frame.
head(charles_data)
```
:::

With a data frame specified, we can then use the `table` function called on it to form a contingency table. 

::: {.content-visible when-format='pdf'}
```{r}
charles_c_table <- table(charles_data)

charles_c_table
```
:::
::: {.content-visible when-format='html'}
```{webr-r}
charles_c_table <- table(charles_data)

charles_c_table
```
:::

Then, to get the totals, we can either use `rowSums` or `colSums` to return a vector with the corresponding row or column sums.

::: {.content-visible when-format='pdf'}
```{r}
marginal_shapes <- colSums(charles_c_table)
marginal_colours <- rowSums(charles_c_table)

marginal_shapes
marginal_colours
```
:::
::: {.content-visible when-format='html'}
```{webr-r}
marginal_shapes <- colSums(charles_c_table)
marginal_colours <- rowSums(charles_c_table)

marginal_shapes
marginal_colours
```
:::

Finally, we can take our formed contingency table, and use `prop.table` on it, in order to return a table with the proportions (rather than the frequencies).

::: {.content-visible when-format='pdf'}
```{r}
charles_p_table <- prop.table(charles_c_table)

charles_p_table
```
:::
::: {.content-visible when-format='html'}
```{webr-r}
charles_p_table <- prop.table(charles_c_table)

charles_p_table
```
:::

## Exercises{.unnumbered}
:::{#exr-4.1}
Four cards are dealt, in order, from a standard pack of $52$ cards.

a. What is the probability that all four are spades?
a. What is the probability that two or fewer are spades?
a. What is the probability that all four are spades, given that the first two are spades?
a. What is the probability that spades and hearts alternate?
:::

:::{#exr-4.2}
Two cards are dealt from a deck of $52$ cards. Find the probability that the second card dealt is a heart.
:::

:::{#exr-4.3}
A manufacturer of computer chips bins their manufactured chips based on the quality. Their production line ends up producing $1$ high quality chip for every $2$ medium quality chips and $2$ low quality chips. That is, the proportions of high-to-medium-to-low remains $1:2:2$. For each quality level of chip, the probability that it is of unacceptable standard is $0$, $0.1$, and $0.2$ respectively. Suppose a bin of chips is selected at random, two chips are tested, and found to be satisfactory.

a. What is the probability it is a high quality bin?
b. What is the probability it is a medium quality bin?
c. What is the probability it is a low quality bin?
:::

:::{#exr-4.4}
Consider the following argument from *Pillow Problems* @Carroll, which purports to prove mathematically that no urn can have two balls of the same colour in it.

> A bag contains 2 counters, as to which nothing is known except that each is either black or white. Ascertain their colours without taking them out of the bag.
>
> We know that, if a bag contained 3 counters, 2 being black and one white, the chance of drawing a black one would be $\dfrac{2}{3}$; and that any other state of things would not give this chance. Now the chances, that the given bag contains ($\alpha$) BB, ($\beta$) BW, ($\gamma$) WW, are respectively $\dfrac{1}{4}$, $\dfrac{1}{2}$, $\dfrac{1}{4}$.
>
> Add a black counter.
>
> Then the chances, that it contains ($\alpha$) BBB, ($\beta$) BWB, ($\gamma$) WWB, are, as before, $\dfrac{1}{4}$, $\dfrac{1}{2}$, $\dfrac{1}{4}$.
>
> Hence, the chance, of now drawing the black one, $$ = \frac{1}{4}\cdot 1 + \frac{1}{2}\cdot\frac{2}{3} + \frac{1}{4}\cdot\frac{1}{3} = \frac{2}{3}.$$
>
> Hence, the bag now contains BBW (since any other state of things would not give this chance).
>
> Hence, before the black counter was added, it contained BW, i.e., one black counter and one white.

a. Show that the probability of drawing a black ball in the described setup is indeed $2/3$.
b. Is the logic sound? Why?
:::

:::{#exr-4.5}
Of people in a certain city who bought a new vehicle in the past year, $12\%$ of them bought an electric vehicle and $5\%$ of them bought an electric truck. Given that a person bought an electric vehicle, what is the probability that it was a truck?
:::

:::{#exr-4.6}
Mo and Fran each roll a die. The person who rolls the highest number wins; if they roll the same number, they both lose. 

a. What is the probability that Fran wins?
a. If Mo rolls a $3$, what is the probability that Mo wins?
a. If Mo rolls a $3$, what is the probability that Fran wins?
a. If Mo wins, what is the probability that Fran rolled a $3$?
a. If Mo wins, what is the probability that Mo rolled a $3$?
:::

:::{#exr-4.7}
A geneticist is studying two genes. Each gene can be either dominant or recessive. A sample of $100$ individuals has $56$ individuals with both genes dominant, $6$ individuals with both genes recessive, $24$ individuals with only gene one dominant, and the remaining $14$ with only gene two dominant. 

a. What is the probability that a randomly sampled individual has dominant gene one?
a. What is the probability that a randomly sampled individual has dominant gene two? 
a. Given that gene one is dominant, what is the probability that gene two is dominant?
a. These genes are said to be in linkage equilibrium if the event that gene one is dominant is independent of the event that gene two is dominant. Are these genes in linkage equilibrium?
:::

:::{#exr-4.8}
A company manufactures electrical components in lots. Suppose that a particular lot of $10$ has $2$ defective components. Let $A$ be the event that the first component drawn is defective, and let $B$ be the event that the second component drawn is defective.

a. What is $P(A)$?
a. What is $P(B|A)$?
a. What is $P(A \cap B)$?
a. What is $P(A^C \cap B)$?
a. What is $P(B)$?
a. Are $A$ and $B$ independent?
a. If the lot had $1000$ components, and $200$ were defective, would it be reasonable to treat $A$ and $B$ as though they are independent? Explain.
:::

:::{#exr-4.9}
A certain delivery service offers both express and standard delivery. Seventy-five percent of parcels are sent by standard delivery, and the rest are sent by express. Of those sent standard, $80\%$ arrive the next day, and of those sent express, $95\%$ arrive the next day. A record of a parcel delivery is chosen at random from the company's files. 

a. What is the probability that the parcel was shipped express and arrived the next day?
a. What is the probability that it arrived the next day?
a. Given the package arrived the next day, what is the probability that it was sent express?
:::

:::{#exr-4.10}
A quality control program at a food production facility involves inspecting finished product for safety. The proportion of items that actually are unsafe is $0.0002$. If an item is unsafe, the probability is $0.995$ that it will fail the inspection. If an item is safe, the probability is $0.99$ that it will pass the inspection. 

a. If an item fails the inspection, what is the probability that it is unsafe?
a. Which of the following is more correct interpretation to the previous answer: 
    i. Most items that fail inspection are safe.
    ii. Most items that pass inspection are unsafe.
a. If an item passes inspection, what is the probability that it is safe?
a. Which of the following is the more correct interpretation to the previous answer:
    i. Most items that fail inspection are unsafe.
    ii. Most items that pass inspection are safe.
a. Explain why a small probability in part (a) is not a problem, so long as the probability in part (c) is large.
:::

:::{#exr-4.11}
A patient goes to see a doctor. The doctor performs a test with $99$ percent reliability--that is, $99$ percent of people who are sick test positive and $99$ percent of the healthy people test negative. The doctor knows that only $1$ in $10000$ people in the country are sick. If the patient tests positive, what are the chances the patient is sick?
:::

:::{#exr-4.12}
Let $A$ and $B$ be events with $P(A) = 0.8$ and $P(A \cap B) = 0.2$. For what value of $P(B)$ will $A$ and $B$ be independent?
:::

:::{#exr-4.13}
Let $A$ and $B$ be events with $P(A) = 0.5$ and $P(A \cap B^C) = 0.4$. For what value of $P(B)$ will $A$ and $B$ be independent?
:::

:::{#exr-4.14}
Prove that if $A\perp B$ then $A\perp B^C$, $A^C \perp B$ and $A^C \perp B^C$.
:::

:::{#exr-4.15}
Show that if $A\perp B$ then $P(A|B) = P(A)$ and $P(B|A) = P(B)$.
:::


::: {.content-visible when-format='html'}

## Self-Assessment {.unnumbered}

Note: the following questions are still experimental. Please contact me if you have any issues with these components. This can be if there are incorrect answers, or if there are any technical concerns. Each question currently has an ID with it, randomized for each version. If you have issues, reporting the specific ID will allow for easier checking!

For each question, you can check your answer using the checkmark button. You can cycle through variants of the question by pressing the arrow icon. 


```{r}
#| echo: false
#| message: false
#| warning: false

library(exams2forms)
set.seed(31415)

```

:::{#sa-4.01}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 12345678900
exams2forms("4.A.IndependenceDefinition.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 20)
```
:::

:::{#sa-4.02}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 12345678900
exams2forms("4.B.PartitionsDefinition.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 20)
```
:::

:::{#sa-4.03}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 123456789

exams2forms("4.C.LawOfTotalProbability.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 20)
```
:::

:::{#sa-4.04}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 123456789

exams2forms("4.D.ConditionalProbability.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 50)
```
:::

:::{#sa-4.05}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 123456789

exams2forms("4.E.2x2Contingency.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 50)
```
:::

:::{#sa-4.06}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 123456789

exams2forms("4.F.LawOfTotalProbability2.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 50)
```
:::

:::{#sa-4.07}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 123456789

exams2forms("4.G.BayesTheorem.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 50)
```
:::

:::{#sa-4.08}
```{r}
#| echo: false
#| message: false
#| results: 'asis'
#| warning: false
#| cache: true
cache_check <- 1234567890

exams2forms("4.H.IndependenceProbabilities.Rmd", 
            edir = "../PracticeQuestions/Chapter4", 
            n = 50)
```
:::

:::

