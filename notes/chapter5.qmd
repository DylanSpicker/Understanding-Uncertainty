# Summarizing Statistical Experiments with Random Variables

## The Need for Random Variables
When introducing probability originally we worked from a sample space and then corresponding events. This is a very general framework which allows us to effectively analyze any statistical experiment. Sample spaces are not restricted to be numeric, for instance, and events are simply subsets of the sample space. As a result, this framework provides the tools for capturing uncertainty quantification in almost any setting. Still, the need to enumerate sample spaces and events over complex sets of arbitrary items is cumbersome and may prevent succinct representations of the underlying phenomena. Often, rather than caring about the entire space of outcomes from an experiment of interest, we are primarily concerned with a summary of the experiment. When we can summarize the experiment using a numerical quantity, we are able to define a random variable. 

:::{#def-random-variable}
## Random Variable
A random variable is a numeric quantity whose specific value depends on chance through the outcome of a statistical experiment. Formally, a random variable is a mapping from the result of an experiment to a set of numbers. 
:::

By reporting the numeric value of the random variable, we are able to summarize the key part of the experiment, succinctly. 

For instance, suppose that we are repeatedly tossing a coin. If we toss the coin $100$ times, then the sample space is going to consist of $2^{100}$ total possible outcomes, each of which is a sequence of $100$ heads and tails.^[Recall our discussions of combinatorics.] Instead, it may be more convenient to assign a random variable to be the number of heads that show up on the $100$ tosses of the coin. In this case, the random variable takes on a non-negative integer between $0$ and $100$. In many situations, such a summary may be all that is relevant from the experiment.

It is important to recognize that information *is* lost when we define this random variable. If $X$ summarizes the number of heads in $100$ tosses of a coin, then provided $X$ you are not able to answer the question "what was the 23rd toss of the coin?" As a result, random variables smooth over the unnecessary information, summarizing the parts of the statistical experiment that we care for. For any statistical experiment, however, we need to carefully define the random variables which are truly of interest to us. 

For instance, if the $23$rd toss of the coin was integral to our decision-making, then perhaps we define a random variable $Y$ which counts the number of heads that show up on the $100$ tosses of the coin, but does so with negative numbers if the $23$rd toss was a tail, and with positive numbers if it was a head. Then, provided $Y$ you can answer "how many heads showed up in the tosses of the coin?" by calculating $|Y|$, and you can answer "what was the $23$rd toss of the coin?" by looking at $\text{sign}(Y)$.

:::{#exm-random-var}
## Random Variables at the Coffee Shop
Back at their favourite coffee shop, Charles and Sadie are sitting in their favourite chairs, discussing random variables and watching the cash register for the inevitable sequence of customers who will arrive there. Charles suggests playing a game together, which is creatively called "how many random variables can we name that have to do with the statistical experiment of watching for customers at a cash register?". Seeing as how catchy the name is, Sadie is excited to play along, and so they start.

Name several distinct random variables which could be observed via the described statistical experiment.

::::{.callout .solution collapse='true'}
## Solution
There are essentially countless different random variables that could be named here, depending on what is of interest. The important concept is that each random variable needs to be a numeric quantity which is calculable from the statistical experiment. For instance:

* The number of people who arrive at the cashier in the next hour.
* The length of time until the next customer arrives at the cashier.
* The amount of money that the next customer spends when paying at the cashier.
* A value of $1$ if the next customer is wearing a hat, and a value of $0$ otherwise.
* The number of different items that are ordered by all customers over the next hour.
* The number of words that the cashier says to the next customer, prior to payment. 
* A count of the number of red items of clothing that can be seen being worn by the next $15$ customers. 
::::
:::

Because of their ability to summarize effectively and flexibly the pertinent components of a statistical experiment, random variables are the default paradigm for discussing randomness. When discussing a random variable we will typically use capital letters, such as $X$, to represent the random quantity with an unknown value. In the event that an experiment is actually performed, and a value is realized for the random variable, we will record this value as a lower case letter, such as $x$. For instance, the number of heads showing in $100$ flips of a coin is an unknown quantity depending on chance which we call $X$. Once we have flipped the coin $100$ times and observed $57$ heads, we denote this as $x=57$.

The importance of this notation is merely to emphasize what values are unknown and random, and what values are known numeric quantities. Because $x$ is a known value taking on some set number we will not often speak of probabilities involving $x$.^[We can actually discuss probabilities revolving around $x$, but they are all deeply uninteresting. Every probability will either be $1$, or $0$. If I tell you that $x = 5$, then $P(x=5) = 1$ and $P(x = 2) = 0$. While this is not a particularly *interesting* probability statement, it is true, and somewhat surprisingly, can arise in meaningful ways.] Instead, we wish to translate the language of probability that we have built to statements regarding the random variable $X$.

The random variable $X$ has a corresponding "sample space" of possible values that it can take on. We will typically refer to this as the *support* of the random variable, though borrowing other terms from math courses (such as *range*) will work also. This support, which we can think of as directly analogous to the sample space of arbitrary elements from before, will depend on the possible realizations from the underlying experiment. We typically will denote the support of a random variable $X$ as $\mathcal{X}$. After the experiment has been performed the random variable will take on a single value from this set.^[The support of a random variable is directly analogous to the sample space from the statistical experiment. That is, it is the set of possible observations which can be made of the random variable. As a result, it is *sometimes* permissible to call the support the "sample space of the random variable", informally. The informality here is important. Formally, a random variable $X$ is a function which maps from the sample space to its support, which is to say $X \colon \mathcal{S}\to\mathcal{X}$.] We can sometimes compactly describe the set of possible values for a random variable, for instance, by stating all the integers, or integers between $5$ and $10$, or even values less than $1000$. This allows for compact descriptions of $\mathcal{X}$ even when the set $\mathcal{S}$ is challenging to describe. The probability of realizing any outcome in $\mathcal{X}$ is dictated by the underlying probability model.

When introducing the concepts of probability we indicated that probability was assigned to events. With random variables, this remains true. As a result we need to define events in terms of random variables. When we have a random variable, $X$, an event is defined as any set of values that it can take on. For instance, we may have the event $X=4$, or the event $X \geq 18$, or the event $2 \leq X \leq 93$, or the event $X \in \{2,4,6,8,10\}$. In each case these are subsets of the possible values that the random variable can take on, based on the outcome of the experiment.^[That is to say, events in the case of random variables are subsets of $\mathcal{X}$.]

Just as before these events can be simple events (comprised of a single outcome) or compound events (consisting of multiple outcomes). The event $\{X=5\}$ is a simple event, whereas the event $\{X \geq 25\}$ is a compound event. With events defined in this way, we can translate the other concepts from the explicit event-based probability. Specifically, we think of the experiment producing a numerical outcome, and then use the same sets of tools as before applied to numeric events.

:::{#exm-rv-recap}
## Expanding on Random Variables at the Coffee Shop
After tiring of their game of "how many random variables can we name that have to do with the statistical experiment of watching for customers at a cash register?", Charles and Sadie fall into a deeper discussion of some of their favourite random variables named during the play through. They take turns describing the support of a chosen random variable, as well as listing examples of simple and compound events that can be translated into the language of random variables.

Choose a random variable identified in @exm-random-var and indicate its support, as well as possible simple and compound events that could be observed in terms of it.

::::{.callout .solution collapse='true'}
## Solution
Suppose that we take $X$ to be a random variable representing "The number of people who arrive at the cashier in the next hour." The support of this random variable is likely best select as the non-negative integers. That is, we take $$\mathcal{X} = \mathbb{N} = \{0,1,2,\dots\}.$$ There may be a reasonable maximal value for the random quantity (such as knowing the number of people who are within an hour radius of the coffee shop, or else knowing the number of people who are presently alive), however, the simpler "all non-negative integers" will likely suffice.

For simple events we may consider $\{X = 0\}$ or $\{X = 10\}$ or $\{X = 31415\}$. In every case, the simple event takes the form $\{X = x\}$.

For compound events we could consider $\{X > 0\}$, representing the event that at least one customer arises, we could consider $\{X \leq 10\}$, the event where no more than $10$ customers show up, or we could consider something a little more abstract, like $X \in \{0, 3, 5, 9, 19, 25\}$ or $X$ is an even number. In all these cases the key point is that compound events have more than one way of being satisfied (in that they correspond to more than one event).
::::
:::

When considering random variables there is a key distinction between two types of random variables, discrete and continuous.

:::{#def-discrete-random-variable}
## Discrete Random Variable
A discrete random variable is any random variable whose support is either finite or else countably infinite.
:::

:::{#def-continuous-random-variable}
## Continuous Random Variable
A continuous random variable is any random variable whose support is uncountably infinite. 
:::

:::{.callout-note icon="false" collapse="true"}
## Countable and Uncountable Sets 
We say that a set is **countable** whenever we can enumerate the elements of the set using the positive integers. If we have a set with a finite number of elements in it, then we say that it is countable because each element in the set can get assigned an integer value (just using $1$ through to the cardinality of the set).

If we take a set like the positive integers, $\{1,2,3,\dots\}$, then this is an infinitely large set. However, it is still countable because we can assign each element of the set an integer value (just use the same integer it is corresponding to!). What if we have the set of positive, even integers (\{2,4,6,8,\dots\})? Each of these is just $2$ times one of the counting numbers, in order, and so these too are countable. 

What if we took the set of real numbers^[Recall that "real numbers" are just all the standard numbers that we think of (decimals, whole numbers, fractions, negative values, etc.).] in the interval $[0,1]$? In this case there is **no way** to map each of these values to the values $\{1,2,3,4,\dots\}$ and as a result the interval $[0,1]$ is **not countable**. It is infinitely large, but it remains infinitely large even after we have enumerated an infinite set of the items in it.

A key difference between countable and uncountable sets is that, with a countable set, we can^[(in principle)] sum over the elements of the set. We cannot sum over the elements of an uncountable set, as there would be no way to actually order and enumerate the items. In these notes, the detailed mathematics of countable versus non-countable sets is tangential to the main point which is in distinguishing between discrete and continuous random variables.
:::

Typically, discrete random variables will take on some collection of the integers, where continuous random variables will be defined on some interval (or set of intervals). That is, we may take discrete random variables to be defined on $\{0,1,2,3,\dots,100\}$ or $\{0,1,2,3,\dots\}$ or $\mathbb{Z}$^[This notation refers to the set of all integers]. For continuous random variables we may take $X \in [0,1]$ or $X \in (0,\infty)$ or $X\in (-\infty,129]$. 

:::{#exm-discrete-vs-continuous-rv}
## The Countability of Coffee Shop Random Variables
Charles and Sadie have been discussing the features of all the random variables they identified at the coffee shop for a long time when Sadie points out that they have not been differentiating between discrete and continuous random variables. Charles thinks "how could we have overlooked this?" and seeks to remedy the situation, immediately!

List at least one discrete and one continuous random variable that could arise via the statistical experiment of watching the cashier at a coffee shop over time (as described in @exm-random-var).

::::{.callout .solution collapse='true'}
## Solution
For this we categorize the random variables originally defined in the solution to @exm-random-var.

*   "The number of people who arrive at the cashier in the next hour." 

    "The number of different items that are ordered by all customers over the next hour."

    "The number of words that the cashier says to the next customer, prior to payment."
    
    "A count of the number of red items of clothing that can be seen being worn by the next $15$ customers. "

    These are all **discrete** random variables, as the only values they can take on are the counting integer values. 

* "The length of time until the next customer arrives at the cashier." This is a **continuous** random variable, as it can take on any value over an interval (say, the interval $(0,28800)$ if the store is open for $8$ hours and the customer were there the whole time).

* "The amount of money that the next customer spends when paying at the cashier." This is a **discrete** random variable, as it must take a finite set of values. One way to make this clear is to count the value in cents, and then it will be only integer values. 

* "A value of $1$ if the next customer is wearing a hat, and a value of $0$ otherwise." This is a **discrete** random variable as it can only be from $\{0,1\}$.
::::
:::

## Probability Distributions and Probability Mass Functions
We will discuss continuous random variables later. For now, we turn our focus to discrete random variables. One of the major utilities of random variables is that they provide a shorthand for summarizing the results of a statistical experiment. To this end, there are several key concepts relating to random variables which help to expedite the analysis of the corresponding probabilities. Chief among these tools is the concept of a probability distribution. 

:::{#def-probability-distribution}
## Probability Distribution
A probability distribution is a mathematical statement describing the probabilistic behaviour of a random variable.
:::

Distributions capture the underlying random behaviour of the random variables of interest, and in so doing, summarize information regarding the experiment or process that is being considered. When concerned with discrete random variables, we typically summarize probability distributions through the use of a probability mass function.

:::{#def-probability-mass-function}
## Probability Mass Function
A probability mass function is a function, $p(x)$, which maps possible values for a discrete random variable (the set $\mathcal{X}$) to the probabilities corresponding to those events.^[That is, $p(x)$ is a function, $p\colon\mathcal{X}\to[0,1]$.]
:::

If a random variable $X$ has support $\mathcal{X} = \{x_1,x_2,\dots,x_k\}$, then a probability mass function is a function $p(x)$ such that $p(x_1) = P(X = x_1)$, $p(x_2) = P(X = x_2)$, and so on through to $p(x_k) = P(X=x_k)$. Once a probability mass function is known, all the probabilistic behaviour of the random variable is fully described.

:::{#exm-probability-mass-function}
## The Coin Game for Three
Sometimes Charlie and Sadie are joined by their friend Garth on their trips to the coffee shop. Also, a probability aficionado, Garth contently joins in the game with Charles and Sadie where three coins are flipped, and depending on the results, one friend pays for the group. Garth's order is typically less than Charles and Sadie and so Sadie proposes the following modified game. 

> A fair coin is tossed three times. If all tosses of the coin show the same symbol, Garth pays. Otherwise, if there are more heads than tails, Charles pays. Finally, if there are more tails than heads, Sadie pays.

Help to simplify this statistical experiment by first defining a random variable, $X$ which can be used to encode this game and then record the probability mass function of $X$.

::::{.callout .solution collapse='true'}
## Solution
One choice of $X$ is to allow $X$ to be the number of heads that show on three tosses of the coin. In this case we have $\mathcal{X} = \{0,1,2,3\}$. If $x = 0$ or $x = 3$ is observed then Garth pays. If $x = 2$ is observed then Charles pays. Finally, if $x = 1$ is observed, Sadie pays. Thus writing down the probability mass function for $X$ also provides an easy way for computing the probability of each player having to pay.

In order for $X = 0$, we must have all tails come up. There are $2^3 = 8$ total possible sequences of $3$ coin tosses, and only $1$ of these results in $X = 0$, therefore $P(X = 0) = p(0) = \dfrac{1}{8}$. The same logic applies to $X = 3$ where we need to toss all heads. There are several techniques for finding $p(1)$ and $p(2)$.^[One particularly elegant technique is to realize that $p(1)$ and $p(2)$ must be the same by interchanging the roles of heads and tails. Thus, we have $p(1) + p(2) + 0.25 = 1$ by the unitary property of probability, and rearranging gives $p(1) = p(2) = 0.375$.] The most direct way is to recognize that there are exactly $3$ ways of observing $1$ head (it can be in the first, second, or third toss). Thus, $p(1) = \dfrac{3}{8}$. For $p(2)$, the same logic applies except we ask "where is the one tail?" to give $p(2) = \dfrac{3}{8}$. Then, taken together, this results in $$p(x) = \begin{cases} 
\dfrac{1}{8} & x \in \{0, 3\} \\
\dfrac{3}{8} & x \in \{1, 2\} \\
0 & \text{otherwise}.\end{cases}$$ We can also read off from this result that Garth pays $\dfrac{1}{4}$ of the time in the long run, while Sadie and Charles each pay $\dfrac{3}{8}$ of the time.^[We can actually write down this probability mass function more succinctly as $p(x) = \binom{3}{x}\dfrac{1}{8}$. You can check this holds for yourself, and we will understand why later on!]
::::
:::

The previously outlined conditions for probabilities must still hold when using probability mass functions. As a result, we know that probabilities are all between $0$ and $1$, and so we must have $0 \leq p(x) \leq 1$, for all $x\in\mathcal{X}$. Moreover, we saw previously that summing the probabilities over the full sample space gave a value of $1$. Correspondingly, we must have that $$\sum_{x\in\mathcal{X}} p(x) = 1.$$ These two properties are often used to define a *valid* probability mass function, and we can use these properties to both check whether a given mass function is valid and to turn a given function into a valid probability mass function.

:::{#exm-finding-a-pmf}
## Charles's Messy Writing Strikes Again
Charles is reading through some notes regarding a new game under development which, like most good games, relies at least a little bit on chance. In the notes there is a probability mass function written down, which, the best Charles can make out, reads $$p(x) = \begin{cases} 3c & x = 0 \\ 0.6 & x = 1 \\ 7c & x = 2.\end{cases}$$ Frustrated with the illegibility, Charles brings the problem to Sadie who points out, if it really is $p(0) = 3c$ and $p(2) = 7c$, they actually have all the information required to solve the problem.

What is the probability mass function, assuming Charles is reading it correctly.

::::{.callout .solution collapse='true'}
## Solution
We know that two properties must be true of all probability mass functions. First $0 \leq p(x) \leq 1$. Second, $\sum_{x\in\mathcal{X}} p(x) = 1$. The first property tells us that $0 < 3c < 1$ and that $0 < 7c < 1$. This means that $c > 0$, and that $c < 1/3$ and $c < 1/7$. Using the second property we get that $$1 = 3c + 0.6 + 7c \implies 0.4 = 10c.$$ This tells us that $c = 0.04$, which satisfies all the previous properties. Taking $c = 0.04$ gives a probability mass function of $$p(x) = \begin{cases} 0.12 & x = 0 \\ 0.6 & x = 1 \\ 0.28 & x = 2.\end{cases}$$ 
::::
:::

When solving questions related to probabilities using a probability mass function, the same secondary properties apply. Notably, if we want to know $P(X\in A)$, for some set of possible values $A$, then we can write $$P(X\in A) = \sum_{x\in A}p(x).$$ This can be particularly helpful, for instance, if we want to know $P(X \leq c)$ for some constant value $c$. In this case we know that the possible values range from the smallest value $X$ can take on, through to $c$, giving for instance, $$P(X\leq c) = \sum_{x=0}^c p(x),$$ if $X \geq 0$. These probabilities, that consider the cumulative likelihood of $X$ taking on a value up to (or including) some number, arise frequently and correspondingly, are themselves named. 

:::{#def-cumulative-distribution-function}
## Cumulative Distribution Function (Discrete)

The cumulative distribution function of a discrete random variable, $X$, is denoted $F_X(x)$, and is defined as the probability that $X$ is less than or equal to a particular value. That is, $$F_X(x) = P(X \leq x) = \sum_{x = -\infty}^x p_X(x).$$ The summation is typically written starting at the smallest value of $X$ rather than starting from $-\infty$.

:::

The cumulative distribution function will be explored more thoroughly in @sec-continuous-rv. Generally, for discrete random variables, the cumulative distribution function is more complex than the probability mass function, and it is often only expressible directly through a summation. Despite this, you can always convert between the probability mass function and the cumulative distribution function, with each uniquely specifying the distribution of the random variable.

The same rules regarding the complements of events continue to hold when working with probability mass functions and cumulative distribution functions. For instance, $$P(X > c) = 1 - P(X\leq c) = 1 - F_X(c),$$ giving a useful avenue for simplifying probability calculations. 

:::{#exm-probability-calc}
## Charles and Sadie: Amateur Ornithologists
Charles and Sadie watched a documentary about birds together, which had Sadie become quite interested in bird watching. Charles is skeptical^[Charles is still not entirely sure if birds are even real, let alone worth watching.] but agrees to go along with Sadie, supposing that there is a high enough probability of something interesting happening. Sadie scours the scholarly literature and determines that, in the area, the probability of seeing $x$ rare birds over a five hour birding session has a probability mass function given by $$p(x) = \dfrac{e^{-3}3^x}{x!},$$ where $x\geq 0$.^[How Sadie found such a concrete answer, I will never know.]

What is the probability that during their bird watching adventure, Charles and Sadie see at least $1$ rare bird?

::::{.callout .solution collapse='true'}
## Solution
We are interesting in the probability $P(X \geq 1)$, which we can write down explicitly as $$P(X \geq 1) = \sum_{x=1}^\infty \dfrac{e^{-3}3^x}{x!}.$$ While, strictly speaking, it is possible to solve this infinite summation, it is an infinite summation, and we would rather not. Instead, we can realize that, if we take the event $A = \{X \geq 1\}$ then $A^C$ is the event $\{X < 1\} = \{X = 0\}$. As a result, using our elementary rules of probability we get that $$P(X \geq 1) = 1 - P(X = 0) = 1 - \dfrac{e^{-3}3^{0}}{0!} = 1 - e^{-3} \approx 0.95.$$ As a result, there is an approximately $0.95$ probability that they see a rare bird while bird watching for five hours.
::::
:::

With events defined in terms of random variables, we can talk about events as being independent of each other or mutually exclusive using the familiar definitions. On a related note, we can talk of joint and conditional probabilities, relating to multiple events. With joint probabilities, it is often easiest to combine the event into a single, compound event, and find the marginal probability of that event. For instance, if you have the events $X$ is even and $X \leq 15$, then the intersection of these events is $X \in \{2,4,6,8,10,12,14\}$ (supposing $X > 0$).

:::{#exm-condition-joint-probability}
## Charles: The Ornithological Photographer
After a single time bird watching Charles is hooked! The next time that they go out, Charles brings a camera to snag some beautiful memories of the majesty they are witnessing. The only trouble is that Charles is not particularly good at taking photographs of still subjects, let alone of creatures that can fly. Charles is not yet certain, but suspects that every time a photograph is snapped, there is a $0.1$ probability that it turns out good. Because the camera is a film camera, the number of photos taken is a key metric, and Charles works out that, if $X$ is the number of bad photographs taken for every good photograph, the probability mass function for $X$ is given by $$p(x) = (0.1)\times (0.9)^{x},$$ where $x \geq 0$ is an integer.

a. What is the probability that Charles takes exactly three bad photos before the first good one?
b. If $A$ is the event that Charles takes three bad photos before the first good one, and $B$ is the event that Charles takes more than four photos before the first good one, what is $P(A,B)$? What does this mean about $A$ and $B$?
c. Suppose that Charles has taken $2$ photos, both of which are bad. What is the probability that at least two more bad photos are taken before a good one?
d. What is the probability that at least $2$ bad photos are taken?
e. Do the results of (c) and (d) suggest an independence?
f. List two events, not previously described, which are independent of one another. 

::::{.callout .solution collapse='true'}
## Solution
a. Here, we want $p(3) = (0.1)\times(0.9)^3 = 0.0729$. 

b. Considering $A \cap B$ we have $\{X = 3\} \cap \{X \geq 4\} = \emptyset$. As a result, $P(A,B) = 0$ since there is no overlap between $A$ and $B$. As a result, these events are mutually exclusive.

c. Here, we can frame this probability as $$P(X \geq 4 | X \geq 2)$$ This can be directly computed using the definition of conditional probability, \begin{align*}
    P(X \geq 4 | X \geq 2) &= \dfrac{P(X \geq 4, X \geq 2)}{P(X \geq 2)} \\
    &= \dfrac{P(X \geq 4)}{1 - P(X < 2)} \\
    &= \dfrac{1 - P(X < 4)}{1 - (0.1 + 0.1\times0.9)} \\
    &= \dfrac{1 - (0.1 + 0.1\times 0.9 + 0.1\times 0.9^2 + 0.1\times0.9^3)}{1 - (0.1 + 0.1\times 0.9)} \\
    &= 0.81.
\end{align*}

d. Through direct calculation we get $$P(X \geq 2) = 1 - P(X < 2) = 1 - (0.1 + 0.1\times 0.9) = 0.81.$$

e. Combining (c) and (d) we find that the probability that an additional two photos are required, given that two have already been taken, is the same as the probability that two photos are required, without knowing that any have been taken. While this feels like an independence type of property, it is not precisely independence. Note that the event $\{X \geq 4\}$ immediately gives the event $\{X \geq 2\}$, and so they cannot be independent of one another.^[Instead of independence, we may describe this distribution as being "memoryless". If you know that you have been waiting a certain amount of time for something to happen (a good picture to get taken) that does not change your belief about how much longer you have to wait; the process "forgets" that it has been ongoing for some time.] For this to be independent we would require $P(A,B) = P(A)P(B)$ which is not true of any of the events discussed.

f. One option is to consider the event $X \geq 0$ with any other event. Because $\{X \geq 0\} = \mathcal{X}$, no information can be gained conditioning on this event. 
::::
:::

## Multiple Random Variables and Joint Probability Mass Functions
While we can discuss independence, joint probabilities, and conditional probabilities relating to events on the same random variable, it is often of interest to combine multiple random variables. Sometimes these random variables will be multiple versions coming from the same distribution, and other times they will be coming from multiple different distributions. In either event, frequently our main concern is in summarizing the probabilistic behaviour of two or more random quantities.

:::{.callout-note icon="false"}
## A Discussion of Distributional Language
Note that when we talk of a random variable "following" a particular distribution, we are saying that the probability mass function of the random variable is described by that distribution's mass function. Thus, if two random variables "share a distribution", we just mean that their probabilistic behaviour is described by the same underlying mass function. 

For instance, if I flip a coin $10$ times, and you flip a different coin $10$ times, and we each count the number of heads that show up, we can say that the random quantity for the number of heads I observe will have the **same distribution** as the random quantity for the number of heads that you observe. 

These two quantities are not equal, in general, but they are described by the same random processes. 
:::

When we describe the distribution of a particular random variable, we are implicitly describing the marginal probabilities associated with that quantity. Just as before, the marginal probabilities describe the behaviour of the random variable alone. What happens when we want to be able to describe multiple components of an experiment, together? For this we require extending the idea of a joint probability beyond the concept of events.

Suppose that we roll two six-sided fair dice. Let $X$ denote the sum of the two dice, and let $Y$ denote the maximum value showing on the two dice. $X$ is a discrete random variable taking on values between $2$ and $12$, while $Y$ is a discrete random variable taking on values between $1$ and $6$. The supports for the two random variables are different from one another and so immediately we know that their probabilistic behaviour must be different, despite the fact that both random variables summarize the same statistical experiment. 

We can also immediately see that the two random variables, while not equal to each other, are dependent. For instance, if you know that $Y=1$ then you know that $X = 2$, and if you know that $Y = 3$, then you know that $X \leq 6$. To begin to capture the joint behaviour of $X$ and $Y$ we introduce the joint distribution and joint probability mass function. 

:::{#def-joint-distribution}
## Joint Distribution
A joint probability distribution describes the joint probabilistic behaviour of two or more random variables, simultaneously.
:::

:::{#def-joint-pmf}
## Joint Probability Mass Function
A joint probability mass function describes the behaviour of the joint distribution of multiple random variables. For a set of random variables, $X_1, \dots, X_n$, the joint probability mass function assigns a probability value for every *tuple* of values that $(X_1,\dots,X_n)$ can take on. 
:::

 The joint probability mass function is analogous to the marginal probability mass function, only it considers joint events rather than marginal ones. Suppose that you have two random variables, $X$ and $Y$. The joint probability mass function assigns a probability value for every pair of values that $(X,Y)$ can take on. That is, $p_{X,Y}(x,y) = P(X = x, Y = y)$. Then, once you know the joint behaviour of $X$ and $Y$, you can fully summarize the combined behaviour of the underlying experiment.

:::{#exm-joint-pmf}
## Charles and Sadie's Bird Outings 
Charles and Sadie have both gotten deeply into their ornithological adventures. They go on trips together, Sadie is responsible for spotting the rare birds, and then Charles for snapping the photos. Charles has settled on a camera setup that allows for $10$ pictures to be taken before changing the film. The strategy that they follow is to go out and look for a rare bird. When one is spotted, Charles takes $10$ photos, trying to get as many good photos as possible. Then, the film is replaced and they repeat the process. 

If $X$ is a random variable representing the number of good photos that are taken, and $Y$ is the number of birds that are seen on the trip, then the joint probability mass function of $X$ and $Y$ is $$p_{X,Y}(x, y) = \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!},$$ with $0 \leq x \leq 10y$, and $y \geq 0$.

a. What is the probability that one bird is seen and there are no good photos taken?
b. What is the probability that there is one or fewer good photos taken and two birds seen?

::::{.callout .solution collapse='true'}
## Solution
a. Here we want $Y = 1$ and $X = 0$. Thus, we compute $$p_{X,Y}(0, 1) = \binom{10(1)}{0}\times(0.25)^{0}\times(0.75)^{10(1) - 0}\times\dfrac{e^{-3}3^1}{1!} \approx 0.008411.$$

b. Here we want $\{X \leq 1\}$ and $Y = 2$. This is the same as $X = 0$ with $Y = 2$ or $X = 1$ with $Y = 2$. Thus, \begin{align*}
p_{X,Y}(0,2) + p_{X,Y}(1,2) &= \binom{10(2)}{0}\times(0.25)^{0}\times(0.75)^{10(2) - 0}\times\dfrac{e^{-3}3^2}{2!} \\
&\quad + \binom{10(2)}{1}\times(0.25)^{1}\times(0.75)^{10(2) - 1}\times\dfrac{e^{-3}3^2}{2!} \\
&\approx 0.00547.\end{align*}

::::
:::

### Joint Probability Distributions as Contingency Tables
In practice, joint probability mass functions can be thought of as analogous to the contingency tables we previously saw. If the first variable represents the first random variable being considered, and the second variable represents the second random variable, then each cell of the contingency table assigns a probability to one of the joint events that could be observed in the experiment. Joint distributions are a useful generalization of contingency tables as they allow us to compactly represent not only two different random variables, but sometimes many more. All of the definitions used for the case of two random variables extend naturally to three, four, and beyond.

:::{#exm-contingency-table-as-joint-pmf}
## Charles and Sadie: Rock-Paper-Scissors Experimentation
Charles and Sadie were once asked if rock-paper-scissors may be an easier way to solve their "who pays for coffee" dilemmas. Though both of them rejected the description of their coffee games as a "dilemma", they had never really given it much thought. One day while bird watching, during a particularly long break with no birds, they begin to think through whether this could work or not. To this end, the friends play $1000$ games, recording the results of each game into a contingency table. They suspect that this provides the true long run proportion of occurrences. To encode these games numerically, they take $X = -1$, $X=0$, and $X=1$ to represent Charles playing rock, paper, and scissors respectively, and they take $Y = -1$, $Y=0$, and $Y=1$ to represent the same events from Sadie.

| | $Y=-1$ | $Y = 0$ | $Y = 1$ |
|-|:-:|:-:|:-:|
|$X=-1$| 400 | 100 | 50 |
|$X=0$| 10 | 200 | 40 |
|$X=1$| 50 | 50 | 100 |

What is the joint probability mass function that corresponds to this contingency table?

::::{.callout .solution collapse='true'}
## Solution
We can explicitly enumerate the possibilities to define the joint probability mass function. That is $$p_{X,Y}(x,y) = \begin{cases}
0.4 & x = -1, y = -1 \\
0.1 & x = -1, y = 0 \\
0.05 & x = -1, y = 1 \\
0.01 & x = 0, y = -1 \\
0.2 & x = 0, y = 0 \\
0.04 & x = 0, y = 1 \\
0.05 & x = 1, y = -1 \\
0.05 & x = 1, y = 0 \\
0.1 & x = 1, y = 1.
\end{cases}$$ While it may be possible to express this in a more compact way, this fits the criteria for a joint probability mass function.
::::
:::

## Independence of Random Variables
If we continue to consider the case of a bivariate (two variable) joint distribution, we can use this setting to introduce the independence of random variables. Recall that the joint probability mass function of $X$ and $Y$ is a function, $p_{X,Y}(x,y) = P(X = x, Y = y)$. We have also introduced the marginal mass functions, $p_X(x) = P(X = x)$ and $p_Y(y) = P(Y = y)$. Further, we have said that two events, $A$ and $B$, are independent if their joint probability is equal to the product of their marginal probabilities, that is $P(A,B) = P(A)P(B)$.

If we take $A=\{X=x'\}$ and $B=\{Y=y'\}$, then if $A\perp B$ we can write $p_{X,Y}(x',y')=p_X(x')p_Y(y')$. If this holds for every possible $x'$ and every possible $y'$, then we say that $X$ and $Y$ are independent random variables, and we write $X \perp Y$.

:::{#def-independent-rv}
## Independent Random Variables
Two random variables, $X$ and $Y$ are said to be independent random variables if their joint probability mass function is given by the product of their marginal probability mass functions, $$p_{X,Y}(x,y) = p_X(x)p_Y(y).$$ We write $X\perp Y$, and read: $X$ is independent of $Y$. 
:::

In words, two random variables are independent whenever all possible combinations of events between them are independent.

:::{#exm-pmf-independence}
## Charles the Sports Fan
Charles is a major sports fan and has been particularly fond of *hurling* ever since a trip to Ireland. Each week, Charles watches with deep investment, becoming very attached to the outcome. Because of this attachment, Charles is willing to do just about anything to help out from behind the television set, which mostly consists of wearing the right coloured clothing. Charles's theory is that by increasing the number of articles of green clothing that are worn, the number of scores in the game will also increase. 

Let $X$ represent the number of articles of green clothing that Charles is wearing, with $X \in \{0,1,2,3,4\}$, and $Y$ is the number of scores in the game. Suppose that $$p_X(x) = \dfrac{(x-2)^2}{10},$$ and that $$p_Y(y) = \dfrac{e^{-45}\times 45^y}{y!}.$$

a. What is the joint probability mass function for $X$ and $Y$, assuming that they are independent?
b. If it is determined that, assuming Charles wears no green clothing, the probability of $50$ scores is $0.01$, are these random variables independent?

::::{.callout .solution collapse='true'}
## Solution
a. If $X\perp Y$, then the joint probability mass function is the product of the two, which is to say $$p_{X,Y}(x,y) = \dfrac{(x-2)^2}{10}\cdot\dfrac{e^{-45}\times 45^y}{y!} = \dfrac{e^{-45}}{10}\times (x-2)^2 \times \dfrac{45^y}{y!}.$$

b. Using the joint probability mass function found in (a), $$p_{X,Y}(0, 15) = \dfrac{e^{-45}}{10}\times (0-2)^2 \times \dfrac{45^{50}}{(50)!} \approx 0.017.$$ This is not equal to $0.01$, and so it must be the case that $X\not\perp Y$.
::::
:::

:::{#exm-independence-arg}
## The Independence Argument
Charles and Sadie are having a disagreement about the nature of the probabilities on their bird outings. Charles claims that, without knowing the marginal probability mass functions of the number of good pictures taken, and the number of rare birds that are seen, there is no way to tell whether the two random quantities are independent or not. Sadie cannot say exactly why this argument feels wrong, but insists that the two quantities must not be independent. 

Who is correct, and why? Recall that $$p_{X,Y}(x, y) = \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!},$$ with $0 \leq x \leq 10y$, and $y \geq 0$

::::{.callout .solution collapse='true'}
## Solution
In this case Sadie is correct. The most clear way of seeing this is by noting that the support set for $X$ depends on $Y$. The question to ask yourself is: how could two functions which are independent of one another multiply together so that one's support depends on the other's? It cannot happen. Put differently: we know that these cannot be independent as, if $Y=0$ then $P(X=0)=1$ as Charles will not take any pictures.
::::
:::

:::{.callout-warning icon="false" collapse="true"}
## Equivalent Definition of Independence
There is an equivalence between the described definition, and a slightly more intuitive definition for independence. 

Whenever $X\perp Y$ any two events corresponding to $X$ and $Y$, say $X \in A$ and $Y \in B$ are independent. The subtle distinction is that in our previous definition, we were only concerned with simple events of the form $X=x'$ or $Y=y'$. Here we allow any two arbitrary events. 

Note that if we have the above definition holding for simple events, then \begin{align*}
P(X \in A, Y \in B) &= \sum_{x\in A}P(X=x,Y\in B) \\
&= \sum_{x\in A}\sum_{y \in B} P(X=x,Y=y)\\
&= \sum_{x\in A}\sum_{y \in B} p_X(x)p_Y(y) \\
&= \left(\sum_{x\in A}p_X(x)\right)\left(\sum_{y\in B}p_Y(y)\right)\\
&= P(X\in A)P(Y\in B).
\end{align*} 

Even by only making the assumption for simple events, the conclusion regarding compound events follows naturally. Whenever any two random variables are known to be independent we know that any two events corresponding to these random variables will be independent. Moreover, we can directly write down the joint probability mass function by taking the product of the two marginals.
:::

## Conditional Probability Distributions
When introducing events, we discussed how the concepts of independence and dependence could be understood more intuitively through the use of conditional probabilities. The same is true for random variables. 

:::{#def-conditional-distribution}
## Conditional Distributions
A conditional distribution of a random variable captures the probabilistic behaviour of a random variable, given information regarding another (or several other) random variables. 
:::

:::{#def-conditional-pmf}
## Conditional Probability Mass Function
A conditional probability mass function assigns probability values associated with any conditional event between multiple random variables. For instance, if there are two random variables $X$ and $Y$, the conditional probability mass function of $X$ given $Y$ characterizes events of the form $X$ given $Y=y$. Mathematically, the conditional mass function is $$p_{X|Y}(x|y) = \dfrac{p_{X,Y}(x,y)}{p_Y(y)}.$$
:::

This definition is analogous to the formula for conditional probabilities more generally, give by the joint distribution over the marginal distribution. To determine the probability of any event (for $X$) given some information about $Y$, you plug-in $X=x$ and $Y=y$ into the conditional probability mass function. If you want to condition on more than one random variable, the quantities extend in exactly the same way, where for instance $$P(X=x|Y=y,Z=z)=\dfrac{P(X=x,Y=y,Z=z)}{P(Y=y,Z=z)}.$$

:::{#exm-conditional-pmf}
## Charles Accepts the Argument
After some convincing, Charles accepts the argument that the number of good pictures taken and the number of rare birds seen cannot be independent events. What really makes this clear, however, is when Sadie points out that the marginal probability mass function for the number of rare birds seen is given by $$p_{Y} = \dfrac{e^{-3}3^y}{y!}.$$ Taken together with the fact that $$p_{X,Y}(x, y) = \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!},$$ with $0 \leq x \leq 10y$, and $y \geq 0$, Charles realizes that the conditional distribution of $X|Y$ can be computed. 

a. What is the conditional probability mass function of $X$ given $Y$?
b. Given that $2$ birds are seen, what is the probability that any good photos are taken?

::::{.callout .solution collapse='true'}
## Solution
a. For the conditional probability mass function we take $p_{X,Y}(x, y)/p_{Y}(y)$$. This gives $$p_{X|Y}(x|y) = \dfrac{\binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!}}{\dfrac{e^{-3}3^y}{y!}} = \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}.$$

b. To represent this, we want $P(X \geq 1 | Y = 2)$. From properties of probability, we know that $P(X \geq 1 | Y = 2) = 1 - P(X < 1 | Y = 2) = P(X = 0 | Y = 2)$, and so using the conditional probability mass function found previously, this gives $$P(X = 0 | Y = 2) = \binom{20}{0}(0.25)^{0}\times(0.75)^{20} = 0.75^{20}.$$ As a result, the probability of interest is $1-0.75^{20} \approx 0.9968$, which is the probability that Charles takes at least one good picture if two birds are seen.
::::
:::

As was discussed, the joint probability mass function of two independent random variables is given by the product of the marginals. If $X\perp Y$, then $p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)$. Combined with the expression for the conditional probability mass function this results in $p_{X|Y}(x|y) = p_X(x)$. That is, whenever two variables are independent, the conditional probability mass function is exactly equal to the marginal probability mass function. 

We saw that this was true for events, and the same reasoning applies here. This result gives an intuitive method for interpreting the independence of random variables. Two random variables are independent whenever any information about the one does not provide information about the other; when they are completely uninformative for one another. With this intuitive description it is easier to infer when independence of random variables is reasonable. Doing so is a useful skill for manipulating probability expressions.

:::{#exm-independence-via-pmfs}
## Charles Exploration of Independence
A little shaken after the previous independence mishap, Charles is committed to better understanding independence at an intuitive level. As a result, every time a pair of random quantities are seen together Charles has taken to deciding whether the underlying random variables would be independent. 

For each of the following, indicate whether the pairs of random quantities are likely to be independent (and why).

a. Charles is buying a butternut squash, and is considering the length of the squash ($X$) and the weight of the squash ($Y$) as the most relevant measurements.
b. Charles is sitting at an intersection which has a separated bike path in front of it, and a lane of vehicular traffic. Take $X$ to be the number of bikes passing by over a length of time, and $Y$ to be the number of cars passing by over a certain time.
c. As the weekend comes around Charles prepares for the hurling match, once again considering whether the number of green items of clothing worn ($X$) has an impact on the number of scores ($Y$).
d. Charles and Sadie are playing battle dice, where Charles rolls a die and compares the result ($X$) to the result of a separate die rolled by Sadie ($Y$).

::::{.callout .solution collapse='true'}
## Solution
a. The length of a butternut squash and its weight are likely dependent. The longer a squash is, all else equal, the more likely it will be heavier, and vice versa. Both of these measure the size of the squash, and as a result, will be connected.

b. This is an interesting example which likely could be argued either way. On one hand, if cars and bikes do not mix, then the traffic of one will not likely impact the traffic on another. However, there are plenty of reasons why a larger number of bikes may suggest a certain number of cars: (1) perhaps more people bike on the weekends and fewer people drive on the weekends; (2) perhaps a city with more bikers has more cars; (3) perhaps more bikes represents a busy time of the day, which would also lead to more cars. It is challenging to know precisely where the impact stems from, it seems likely that there would be some relationship.

c. There is likely no impact of what Charles is doing and what is happening in a sporting match being watched on the TV. As a result, these two quantities should be independent. 

d. The die roll from Charles has no impact on the die roll from Sadie, and vice versa. As a result, these two random variables will almost certainly be independent.

::::
:::

## Manipulating Probabilities with Random Variables
Seeing as the joint, marginal, and conditional probability mass functions are exactly analogous to the corresponding concepts when they were introduced regarding events, it is reasonable to assume that we can extend the multiplication rule, the law of total probability, and Bayes' theorem to the framework of probability functions. Indeed, each of these relationships continues to hold for random variables in much the way that would be expected.

:::{.callout-tip icon="false"}
## Multiplication Rule (with Probability Mass Functions)
Translating the multiplication rule to use probability mass functions gives $$p_{X,Y}(x,y) = p_{X|Y}(x|y)p_Y(y) = p_{Y|X}(y|x)p_X(x).$$ This can be seen by rearranging the relationship defining the conditional probabilities. 
:::

:::{.callout-tip icon="false"}
## Bayes' Theorem (with Probability Mass Functions)
Bayes' Theorem can be rewritten using probability mass functions as well. Specifically, $$p_{Y|X}(y|x) = \dfrac{p_{X|Y}(x|y)p_Y(y)}{p_X(x)}.$$ This follows directly from the definition of conditional probabilities, as well as the multiplication rule.
:::

These rules give the ability to compute the joint distribution and the other conditional information, when we have information regarding some of the marginals and some of the conditionals. These properties are used less *explicitly* when dealing with probability mass functions directly. Instead, they almost become absorbed into the fabric of the defining relationships themselves. That is to say, you are less likely to see Bayes' theorem invoked directly when moving between conditional distributions; however, moving between conditional distributions *is* an important skill, and requires the use of Bayes' Theorem.

:::{#exm-pmg-multiplication-and-bayes}
## Charles and the Chores 
Charles has decided to take a break from having paid employment, instead taking time to help ensure that Sadie's house runs smoothly as Sadie has been busy trying to write a novel. Unfortunately, sometimes chores are not done in a timely manner, despite Charles's best efforts. While Sadie has been nothing but supportive, Charles decides to turn to probability to ease uncertainties. 

Define $X=1$ if a given chore was done by Charles, with $X=0$ if it was done by Sadie. Let $Y=1$ denote a chore being done on time with $Y = 0$ if it was late. Suppose that \begin{align*}
p_{Y|X}(y|x) &= (0.5 + 0.4x)^{y}\times(0.5 - 0.4x)^{1-y},\\
p_X(x) &= 0.85^{x}\times(0.15)^{1-x},\\
p_Y(y) &= .85\times(0.9)^y(0.1)^{1-y} + 0.075.
\end{align*}

a. What is the probability that a chore is late and done by Charles?
b. What is the probability that, given a chore was done by Charles, it was done late? What about with Sadie?
c. What is the probability that, given a chore was late, it was done by Charles? What about with Sadie?
d. Explain how the results of (b) and (c) may result in Charles feeling responsible for the late chores. Is that accurate?

::::{.callout .solution collapse='true'}
## Solution
a. For this question, we require the joint probability mass function we apply the product rule. That is, $$p_{X,Y}(x,y) = p_{Y|X}(y|x)p_{X}(x) = (0.5 + 0.4x)^{y}\times(0.5 - 0.4x)^{1-y}\times0.85^{x}\times(0.15)^{1-x}.$$ Then, to find the probability that a chore is late and done by Charles we take $p_{X,Y}(1,0) = 0.1\times 0.85 = 0.085.$

b. For Charles, we want $P(Y=0|X=1)$, which can be solved for directly using the provided conditional probability mass function. That is, $$p_{Y|X}(0|1) = (0.5 + 0.4)^{0}\times(0.5 - 0.4)^{1} = 0.1.$$ For Sadie, we want $P(Y=0|X=0)$. This gives $$p_{Y|X}(0|0) = (0.5)^{0}\times(0.5)^{1} = 0.5.$$ 

c. Here we require the alternative conditional distribution, $P(X|Y)$. For this we can leverage Bayes' Theorem. Specifically, $$p_{X|Y} = \dfrac{p_{Y|X}(y|x)p_{X}(x)}{p_{Y}(y)} = \dfrac{(0.5 + 0.4x)^{y}\times(0.5 - 0.4x)^{1-y}\times0.85^{x}\times(0.15)^{1-x}}{.85\times(0.9)^y(0.1)^{1-y} + 0.075}.$$ Then, the probability that Charles did the chore, given it was late, is $p_{X|Y}(1|0) = 0.53125$ and the probability that Sadie did the chore, given it was late, is $p_{X|Y}(0|0) = 0.46875$. 

d. Two things are true with the given probabilities. First, if a chore was done late, it was more likely done by Charles than Sadie. Second, Sadie is more likely to do chores late than Charles. This explains why Charles may feel responsibility for the late chores: a higher proportion of late chores are Charles's chores. However, that is only because Charles does so many more chores to begin (the probability that Charles does a chore is $0.85$).^[This is another example of *confusion of the inverse*.] 
::::
:::

Unlike the multiplication rule and Bayes' theorem, the extension of the law of total probability is frequently cited when manipulating probability mass functions. It is a process which is important enough to warrant its own name: marginalization.

:::{.callout-tip icon="false"}
## Marginalization
The idea with marginalization is that we are going to take a joint probability mass function and *marginalize it*, turning it into a marginal distribution. This is analogous to the law of total probability. 

When dealing with a random variable, $Y$, there is some set of numeric values that $Y$ can take on, namely the support of $Y$, which we denote $\mathcal{Y}$. A natural partition of the space is to then take each possible value for $Y$ as the event, and enumerate through the elements of $\mathcal{Y}$.

Using this partition, we can ask about the ways that $X$ can take on any particular value. In order for $X$ to be some specific value, $x'$, we know that $Y$ must be one of the values, $y'\in\mathcal{Y}$. Thus, if we add up all the possible combinations, $(X=x',Y=y_1)$, $(X=x',Y=y_2)$, and so forth, we will have covered every possible way of making $X=x'$. This is the exact same process we used when looking at contingency tables, where we summed a row or column to get the marginal probabilities.

![This graphic shows the partitioning of the sample space using a random variable. It is entirely analogous to @fig-basic-partition, where in place of many different events, we partition over the set of values for $Y$. Here, $\mathcal{Y} = \{1,2,3,4,5,6,7\}$.](/graphics/ch5-basic-partition){#fig-basic-partition-rv}

Taking this argument and encoding it with mathematical notation we get that $$P(X=x) = \sum_{y\in\mathcal{Y}} P(X=x, Y=y) \implies p_X(x) = \sum_{y\in\mathcal{Y}} p_{X,Y}(x,y).$$ The process of marginalization involves summing over one of the random variables in a joint distribution, leaving behind only the marginal of the other. This is often a very effective way of determining a marginal distribution when information about two random variables is easier to discern than information about only one.

To complete the analogy to the law of total probability, recall that the multiplication rule tells us that $p_{X,Y}(x,y) = p_{X|Y}(x|y)p_Y(y)$, and so we may also marginalize by taking $$p_X(x) = \sum_{y\in\mathcal{Y}} p_{X|Y}(x|y)p_Y(y).$$ This makes it clear that marginalization is often accomplished via arguments based on conditioning.
:::

When confronted with questions from statistics and probability, it will often be the case that the natural answer to the question is "it depends." For instance, if asked "what is the probability that a student passes their next exam?" the likely response is "it depends." One very useful technique for solving these questions satisfactorily is to continue that line of thought and explicitly specify "on what." In the previous example, you may say "it depends on how much they study." The conceit here is that, if you knew how much the student studied, then you would better understand the outcomes of the student's exam. 

In mathematical terms this means you have a firm belief about the conditional distribution between the random quantities of *exam performance* and *study time*. The process of marginalization, and the law of total probability before that, provide useful ways of being able to translate these "it depends" statements into concrete beliefs about the marginal probabilities. Recall that marginal distributions are distributions which do not depend on any other quantity, and instead, they capture the overall behaviour of a random variable. They have, in some sense, averaged out all other factors and give you the beliefs which do not depend on anything else at all. The technique for accomplishing this is marginalization.^[We shall see other forms of these "conditioning arguments" in the next chapter, where we try to summarize the behaviour of a random variable.]

:::{#exm-conditioning}
## Photos and Bird Sightings on their Own
Recall that when Charles and Sadie go on their bird watching adventures, Charles takes photos hoping for as many good ones as possible, and Sadie spots the birds. We take $X$ to be the number of good photos taken on these trips, and $Y$ to be the number of rare birds that are seen. We noted that $$p_{X,Y}(x, y) = \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!},$$ with $0 \leq x \leq 10y$, and $y \geq 0$.

a. Write down an expression for the marginal probability mass function of $Y$.
b. Write down an expression for the marginal probability mass function of $X$.
c. **Challenge:** solve for the marginal probability mass function of $Y$. 

::::{.callout .solution collapse='true'}
## Solution
a. To find $p_Y(y)$, we marginalize over $X$. That is, we sum the joint probability distribution function over all values for $X$. This gives $$p_Y(y) = \sum_{x = 0}^{10y} p_{X,Y}(x, y) = \sum_{x = 0}^{10y} \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!}.$$

b. To find $p_X(x)$, we marginalize over $Y$. That is, we sum the joint probability distribution function over all values for $Y$. This gives $$p_X(x) = \sum_{y = 0}^{\infty} p_{X,Y}(x, y) = \sum_{y = 0}^{\infty} \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!}.$$

c. Note, that you will generally not be expected to manipulate these types of sums, however, it is possible to do. First, for $p_Y(y)$, \begin{align*}
p_Y(y) &= \sum_{x = 0}^{10y} \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}\times\dfrac{e^{-3}3^y}{y!} \\
&= \dfrac{e^{-3}3^y}{y!}\underbrace{\sum_{x = 0}^{10y} \binom{10y}{x}\times(0.25)^{x}\times(0.75)^{10y - x}}_{=1} \\
&= \dfrac{e^{-3}3^y}{y!}.
\end{align*}
::::
:::

## Independent and Identically Distributed: A Framework for Interpretation
A very common assumption when addressing questions in statistics and in probability is that we have a set of random variables which are independent and identically distributed (often written iid). We now have the tools to understand concretely what this means. 

:::{#def-iid}
## Independent and Identically Distributed (iid)
A set of random variables, $X_1,X_2,\dots,X_n$ are said to be independent and identically distributed (denoted iid) whenever:

i. every subset of random variables in the collection is independent of every other subset of random variables in the collection; and 
ii. the marginal distribution for each of the random variables are exactly the same. 
:::

The assumption of iid random quantities will often come up when we are repeating a process many times over, and thinking about what observations will arise from this. Suppose that $X_1$ is a random variable that takes the value $1$ if a flipped coin comes up heads, and $0$ otherwise. If we imagine flipping this coin $100$ times then it is reasonable to assume that each sequential coin flip will be independent of each other coin flip, since the result on one flip of a coin should not influence the result of any other flip of a coin. Moreover, every time the coin is flipped, it is reasonable to assume that the probability it shows up heads remains the same. As a result, these $100$ random quantities, ($X_1, X_2, \dots, X_{100}$), are said to be iid.

:::{#exm-iid}
## Reframing the Bird Photos
Charles and Sadie had, to this point, been considering their bird photo taking adventures in terms of the joint and conditional distributions. After learning of independent and identically distributed random variables, Charles thinks that there is another way to frame the setup, and describes the following to Sadie:

> Suppose it is known that there will be $y$ birds seen on any given day. Then, the total number of good pictures of birds can be viewed as the sum of the number of good pictures of each bird. Thus, we can take a set of iid random variables, say $X_1,\dots,X_y$ which represent the number of good pictures taken of each bird. 

a. Is this an accurate description? In reality, do we think that this will hold?
b. Supposing that this description is accurate, and that the probability mass function for each $X_j$ is given by $$p_X(x) = \binom{10}{x}(0.25)^{x}(0.75)^{10-x},$$ what is the joint probability mass function of $(X_1,\dots,X_y)$?

::::{.callout .solution collapse='true'}
## Solution
a. Yes, this is a reasonable explanation. In this case, if Charles is willing to assume that good photos for one bird do not impact the chances of good photos of another bird, then this is a perfectly valid way to frame the setting. Note that in this case, $Y=y$ is still random, so this whole description is conditioning on knowing $Y=y$. In the real world, it is likely that photos may not actually be independent. If Charles takes some really bad photos of one bird, that may impact the chances of taking good photos of the next. However, it is likely close enough to correct in order to be true.

b. Recall that for independent random variables, the joint probability mass function is given by the product of the marginal probability mass functions. To simplify the notation, we will define $T(X) = \sum_{i=1}^y x_i$. Thus, the probability mass function of $X_1,\dots,X_y$ is given by \begin{align*}
    p_{X_1,X_2,\dots,X_y}(x_1,\dots,x_y) &= \prod_{i=1}^y \binom{10}{x_i}(0.25)^{x_i}(0.75)^{10-x_i} \\
    &= \left(\prod_{i=1}^y\binom{10}{x_i}\right)\times(0.25)^{\sum_{i=1}^y x_i}(0.75)^{10y - \sum_{i=1}^yx_i} \\
    &= \left(\prod_{i=1}^y \dfrac{10!}{x_i!(10-x_i)!}\right)\times 0.25^{T(X)}\times 0.75^{10y - T(X)} \\
    &= \left(\dfrac{(10!)^y}{\prod_{i=1}^y x_i!(10 - x_i)!}\right)\times 0.25^{T(X)}\times 0.75^{10y - T(X)}.
\end{align*}

::::
:::

While we will use the assumption of iid random variables explicitly at a later point, the iid assumption also provides an intuitive method for interpreting probability functions and distributions. 

Suppose that we were to take a probability mass function, $p_X(x)$. If we were able to generate independent and identically distributed realizations from this probability mass function, then the function $p_X(x)$ describes the behaviour for these repeated realizations. Specifically, $p_X(x)$ will give the long-run proportion of realizations of the iid random variables which take the value $x$.

This type of statement is always the flavour of interpretation statements that are made with respect to probability and statistics. It is always be the case that, in order to understand what is meant by a statement of probability, we consider the repetition of some statistical experiment over and over again. When we were discussing sample spaces and experiments directly, we talked about repeating the experiment over and over again. When we begin to work with random variables instead, it becomes more natural to think about the replication procedures coming through the use of independent and identically distributed random variables. 

As your study of probability progresses, you will begin to work with random quantities in a strictly theoretical sense. In introductory level problems, we are often holding in mind very concrete examples to illustrate the procedures and concepts. In this setting it is easy enough to hold in mind the experiment of interest: for instance, we may have a random variable representing the result of a coin toss, and you can envision repeatedly tossing a coin. As the concepts become less concrete, more abstract, and harder to draw direct parallels to tangible scenarios, it becomes more and more important to rely on the interpretations rooted in a series of independent and identically distributed random variables. 

A large component of statistics as an area of study is making explicit the assumptions we are working with, and doing our best to ensure that these are reasonable. By interpreting probability mass functions as the proportion of independent and identically distributed random variables that take on a particular value when we repeatedly take realizations of these random variables, this philosophy is made clear and explicit.

## Exercises{.unnumbered}

:::{#exr-5.1}
Suppose that you sit in the library, observing the front desk until a patron takes out books. Describe at least $5$ different random variables that could correspond to this experiment.
:::

:::{#exr-5.2}
Consider the data collection that goes on at a weather station. Describe as many different random variables as you can think of corresponding to this experiment.
:::

:::{#exr-5.3}
For each of the following random variables, identify whether they are discrete or continuous.

a. In a survey, the number of siblings each participant has is recorded.
a. A thermometer measures temperature in degrees Celsius.
a. The number of cars passing through a toll booth in an hour.
a. In a casino game, the amount of money won or lost on a single bet.
a. The weight of apples harvested from an orchard.
a. In a classroom, the number of students who own a laptop.
a. The time it takes for a light bulb to burn out.
a. When flipping a coin, the number of heads obtained in $10$ flips.
a. The height of students in a class. 
a. The number of emails received per day.
a. In a factory, the number of defective products in a batch.
a. The distance traveled by a car in a specific time interval.
a. When selecting a card from a standard deck, the card's face value.
a. The age at which individuals first learn to ride a bicycle.
a. The number of customers entering a store in one hour.
a. In a soccer match, the time it takes for the first goal to be scored.
a. The number of books a person reads in a month.
a. When rolling two dice, the sum of the numbers rolled.
a. The number of text messages sent in a day.
a. The volume of water in a reservoir.
:::

:::{#exr-5.4}
Suppose that a probability mass function is given by $$p(x) = \begin{cases}
    k(7x + 3) & x = 0, 1, 2, 3\\
    0 & \text{otherwise}
\end{cases}.$$ Find the value of $k$. 
:::

:::{#exr-5.5}
Consider a probability mass function given by $$p(x) = \begin{cases}
    z & x = 1 \\
    \dfrac{1}{x^2} & x = 2, 3, 4, 5, 6, 7, 8, 9, 10 \\
    0 & \text{otherwise}
\end{cases}.$$

a. Find $z$.
a. What is the probability that $X$ is an even number?
:::

:::{#exr-5.6}
Consider the probability mass function, defined for all non-negative integers, given by $$p(x) = \dfrac{2^xe^{-2}}{x!}.$$

a. What is $P(X = 0)$?
a. What is $P(X = 5)$?
a. What is $P(X \geq 2)$?
:::

:::{#exr-5.7}
For each of the following, indicate and explain whether the following properties could belong to a valid probability mass function.

a. $p(x) < 0$ for some $x \in \mathbb{Z}$.
a. $p(x) > 1$ for some $x \in\mathbb{Z}$.
a. $p(x) > \dfrac{\pi}{\ell}$ for all elements of an $\ell$ element set.
a. $p(-|x|) > 0$ for all $x\in\mathbb{Z}$.
:::

:::{#exr-5.8}
Suppose that, for some fixed integer, $y$, you define the mathematical function $p(x) = \delta_y = I(x = y)$. That is, it takes a value of $1$ if $x = y$ and $0$ otherwise. Is this a valid probability mass function? Why?
:::

::: {#exr-5.9}
Consider the joint probability mass function of two random variables, $X$ and $Y$, given by $$P(X=x, Y=y) = \dfrac{1}{150}(x + y), 1\leq x, y\leq 5.$$

a. Show that this is a valid joint probability mass function. 
b. What is $P(X = 2, Y = 3)$?
c. What is the $P(X = 4)$?
d. What is the marginal probability mass function of $Y$?
d. Are $X$ and $Y$ independent? Explain.
e. What is the conditional probability mass function of $X$ given $Y$?
f. What is the conditional probability mass function of $Y$ given $X$?
:::

::: {#exr-5.10}
Consider the joint probability mass function of two random variables, $X$ and $Y$, given by $$P(X=x, Y=y) = \dfrac{1}{12}(y - x)^2, 1\leq x, y\leq 3.$$

a. Show that this is a valid joint probability mass function. 
b. What is $P(X = 1, Y = 2)$?
c. What is the $P(X = 2)$?
d. What is the marginal probability mass function of $Y$?
d. Are $X$ and $Y$ independent? Explain.
e. What is the conditional probability mass function of $X$ given $Y$?
f. What is the conditional probability mass function of $Y$ given $X$?
:::

::: {#exr-5.11}
Consider the following joint probability mass function represented as a contingency table:

$$
\begin{array}{c|ccc}
    & Y = 1 & Y = 2 & Y = 3 \\
\hline
X = 1 & 0.1 & 0.2 & 0.3 \\
X = 2 & 0.2 & 0.1 & 0.1 \\
\end{array}
$$

a. What is the probability that $X = 1$ and $Y = 2$?
b. Calculate $P(X = 2)$.
c. Find the marginal probability mass function of $Y$.
d. Are $X$ and $Y$ independent? Justify your answer.
e. What is $P(Y=1|X=2)$?
f. What is $P(X = 2| Y = 2)$?
:::

::: {#exr-5.12}
Suppose that a particular disease is associated with two common types of genetic mutations, say type $A$ and type $B$. Let $A$ and $B$ correspond to the random variables which count the locations at which each type of mutation has occurred. In order for a type $B$ mutation to occur, a type $A$ must have also occurred at the same location, and so we can say that $$P(B=b|A=a) = \binom{a}{b}(0.25)^b(0.75)^{a-b}, \quad b\in\{0,1,2,\dots, a\}.$$ Moreover, suppose that $$P(A=a) = \dfrac{10-a}{45} \quad a\in\{0,1,2,3,4,5\}.$$

a. What is the joint probability mass function of $A$ and $B$?
b. What is the marginal probability mass function of $B$?
c. What is the conditional probability mass function of $A$ given $B$?
d. Is $B$ independent of $A$? Explain.
e. Is $A$ independent of $B$? Explain.
f. Suppose that you are at a substantially increased risk of the disease if the total, $A+B \geq 8$. What is the probability that an individual is at an increased risk?
:::

::: {#exr-5.13}
Suppose a factory produces two types of products: Widgets and Gadgets. Let $W$ and $G$ represent the random variables denoting the number of units produced for each type, in a particular hour. Suppose that the following is observed as the joint probability mass function $$P(W=w, G=g) = \dfrac{1}{80}, \quad w \in \{1,2,3,\dots,8\}, g \in \{1,2,3,\dots,10\}.$$

a. What is the marginal probability mass function, $P(W)$?
b. What is the marginal probability mass function, $P(G)$?
c. Is $W\perp G$?
d. Let $T = W + G$. What is the probability mass function of $T$?
e. What is the conditional probability mass function, $P(W|T)$?
f. What is the conditional probability mass function, $P(G|T)$?
g. What is the conditional probability mass function, $P(T|G)$?
h. What is the conditional probability mass function, $P(T|W)$?
:::


::: {#exr-5.14}
a. List an example of a real-world scenario where a set of random variables is likely to be iid. Explain.
b. List an example of a real-world scenario where a set of random variables is likely to be identically distributed, but not independent. Explain.
c. List an example of a real-world scenario where a set of random variables is likely to be independent, but not identically distributed. Explain.
:::

::: {#exr-5.15}
Suppose that $X$ and $Y$ are iid, with $p_X(x)$ and $p_Y(y)$. If $Y$ takes on a specific value, $y'$, with $p_Y(y') = 0.25$, what is the probability that $X$ takes on the same value? Explain.
:::

::: {#exr-5.16}
Suppose that $X_1,\dots,X_n$ are iid with a probability mass function, $p_X(x)$.

a. What is the joint probability mass function of $(X_1,\dots,X_n)$?
b. What is the conditional probability mass function, $P(X_1 = x | X_2 = y)$?
c. What is the probability mass function of $X_1$ conditional on $\sum_{i=2}^n X_i$?
:::