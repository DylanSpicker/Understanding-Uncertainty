<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT 1793: Course Notes - 7&nbsp; Expectations and Variances with Multiple Random Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notes/chapter8.html" rel="next">
<link href="../notes/chapter6.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter7.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Expectations and Variances with Multiple Random Variables</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">STAT 1793: Course Notes</a> 
        <div class="sidebar-tools-main">
    <a href="../STAT-1793--Course-Notes.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part 1: Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Mathematical Foundations of Statistical Experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Core Concepts of Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probabilities with More than One Event</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Summarizing Statistical Experiments with Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Expected Value, Location Summaries, and Measures of Variability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter7.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Expectations and Variances with Multiple Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Named Discrete Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Continuous Random Variables</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Part 2: Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduction to Statistics</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#conditional-expectation" id="toc-conditional-expectation" class="nav-link active" data-scroll-target="#conditional-expectation"><span class="header-section-number">7.1</span> Conditional Expectation</a></li>
  <li><a href="#conditional-expectations-as-random-variables" id="toc-conditional-expectations-as-random-variables" class="nav-link" data-scroll-target="#conditional-expectations-as-random-variables"><span class="header-section-number">7.2</span> Conditional Expectations as Random Variables</a></li>
  <li><a href="#conditional-variance" id="toc-conditional-variance" class="nav-link" data-scroll-target="#conditional-variance"><span class="header-section-number">7.3</span> Conditional Variance</a></li>
  <li><a href="#joint-expectations" id="toc-joint-expectations" class="nav-link" data-scroll-target="#joint-expectations"><span class="header-section-number">7.4</span> Joint Expectations</a>
  <ul class="collapse">
  <li><a href="#linear-combinations-of-random-variables" id="toc-linear-combinations-of-random-variables" class="nav-link" data-scroll-target="#linear-combinations-of-random-variables"><span class="header-section-number">7.4.1</span> Linear Combinations of Random Variables</a></li>
  </ul></li>
  <li><a href="#expectations-when-random-variables-are-independent" id="toc-expectations-when-random-variables-are-independent" class="nav-link" data-scroll-target="#expectations-when-random-variables-are-independent"><span class="header-section-number">7.5</span> Expectations when Random Variables are Independent</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter7.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Expectations and Variances with Multiple Random Variables</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Expectations and Variances with Multiple Random Variables</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="conditional-expectation" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="conditional-expectation"><span class="header-section-number">7.1</span> Conditional Expectation</h2>
<p>Up until this point we have considered the marginal probability distribution when exploring the measures of central tendency and spread. These help to summarize the marginal behaviour of a random quantity, capturing the distribution of <span class="math inline">\(X\)</span> alone. When introducing distributions, we also made a point to introduce the conditional distribution as one which is particularly relevant when there is extra information. The question “what do we expect to happen, given that we have an additional piece of information?” is not only well-defined, but it is an incredibly common type of question to ask.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> To answer it, we require <strong>conditional expectations</strong>.</p>
<div id="def-conditional-expectation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7.1</strong></span> The conditional expectation of a random variable, <span class="math inline">\(X\)</span>, given a second random variable, <span class="math inline">\(Y\)</span>, is the average value of <span class="math inline">\(X\)</span> when we know the value of <span class="math inline">\(Y\)</span>. Specifically, we write <span class="math inline">\(E[X|Y]\)</span>, and define this to be <span class="math display">\[E[X|Y] = \sum_{x\in\mathcal{X}} xp_{X|Y}(x|y),\]</span> which is exactly analogous to the defining relationship for <span class="math inline">\(E[X]\)</span>, replacing the marginal probability mass function with the conditional probability mass function.</p>
</div>
<p>In principle, a conditional expectation is no more challenging to calculate than a marginal expectation. Suppose we want to know the expected value of <span class="math inline">\(X\)</span> assuming that we know that a second random quantity, <span class="math inline">\(Y\)</span> has taken on the value <span class="math inline">\(y\)</span>. We write this as <span class="math inline">\(E[X|Y=y]\)</span>, and we replace <span class="math inline">\(p_X(x)\)</span> with <span class="math inline">\(p_{X|Y}(x|y)\)</span> in the defining relationship. That is <span class="math display">\[E[X|Y=y] = \sum_{x\in\mathcal{X}}xp_{X|Y}(x|y).\]</span> We can think of the conditional distribution of <span class="math inline">\(X|Y=y\)</span> as simply being a distribution itself, and then work with that no differently. The conditional variance, which we denote <span class="math inline">\(\text{var}(X|Y=y)\)</span> is defined in an exactly analogous manner, giving <span class="math display">\[\text{var}(X|Y) = E[(X - E[X|Y])^2|Y].\]</span></p>
<p>Above we supposed that we knew that <span class="math inline">\(Y=y\)</span>. However, sometimes we want to work with the conditional distribution more generally. That is, we want to investigate the behaviour of <span class="math inline">\(X|Y\)</span>, without yet knowing what <span class="math inline">\(Y\)</span> equals. We can use the same procedure as above, however, this time we leave <span class="math inline">\(Y\)</span> unspecified. We denote this as <span class="math inline">\(E[X|Y]\)</span>, and this expression will be a function of <span class="math inline">\(Y\)</span>. Then, whenever a value for <span class="math inline">\(Y\)</span> is observed, we can specify <span class="math inline">\(Y=y\)</span>, deriving the specific value. We will typically compute <span class="math inline">\(E[X|Y]\)</span> rather than <span class="math inline">\(E[X|Y=y]\)</span>, since once we have <span class="math inline">\(E[X|Y]\)</span> we can easily find <span class="math inline">\(E[X|Y=y]\)</span> for <em>every</em> value of <span class="math inline">\(y\)</span>.</p>
<div id="exm-conditional-expectation" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 (Charles Commences Crocheting)</strong></span> Charles has recently taking up crocheting, but as it is a new skill, is still in the phase of learning where mistakes are somewhat common. When sitting down to practice, the number of rows that Charles can complete in an hour is being recorded by Sadie, as a random quantity <span class="math inline">\(X\)</span>. After these have been completed, Charles goes back through and counts the number of mistakes that were made, recording this as <span class="math inline">\(Y\)</span>. In their experiments they find that <span class="math display">\[p_{X,Y}(x,y) = \frac{44800}{854769} \frac{1}{(x-y)!y!} \left(\frac{21}{10}\right)^x\left(\frac{3}{7}\right)^{y}, \]</span> for <span class="math inline">\(x \in \{1,2,3,\dots,10\}\)</span> and <span class="math inline">\(y \in\{0,1,2,\dots,y\}\)</span>. Sadie works out that <span class="math display">\[p_X(x) = \frac{44800}{854769} \frac{3^x}{x!}, \quad x\in\{1,2,3,\dots,10\}.\]</span></p>
<ol type="a">
<li>How could Sadie have worked out <span class="math inline">\(p_X(x)\)</span>? You do not need to actually compute it.</li>
<li>If we know that <span class="math inline">\(X = 3\)</span>, what is the expected value of <span class="math inline">\(Y\)</span>?</li>
<li>Generally, given <span class="math inline">\(X\)</span>, write down an expression for the expected value of <span class="math inline">\(Y\)</span>.</li>
<li><strong>Challenge:</strong> Can you simplify the expression in (c)? It may be useful to know that <span class="math inline">\(k\dbinom{n}{k} = n\dbinom{n-1}{k-1}\)</span>.</li>
<li>What is the variance of <span class="math inline">\(Y\)</span>, when <span class="math inline">\(X=3\)</span>?</li>
</ol>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li>Sadie could have used the process of marginalization. That is, <span class="math display">\[p_X(x) = \sum_{y = 0}^{x} p_{X,Y}(x,y) = \sum_{y=0}^{x} \frac{44800}{854769} \frac{1}{(x-y)!y!} \left(\frac{21}{10}\right)^x\left(\frac{3}{7}\right)^{y}.\]</span></li>
<li>We want <span class="math inline">\(E[Y|X=3]\)</span>. For this, we can use <span class="math inline">\(p_{Y|X}(y|3)\)</span> as the distribution, which is expressible as <span class="math display">\[p_{Y|X}(y|3) = \frac{\frac{44800}{854769} \frac{1}{(3-y)!y!} \left(\frac{21}{10}\right)^3\left(\frac{3}{7}\right)^{y}}{\frac{44800}{854769} \frac{3^{3}}{(3)!}} = \left(\frac{7}{10}\right)^3\binom{3}{y}\left(\frac{3}{7}\right)^y,\]</span> where <span class="math inline">\(y \in \{0,1,2,3\}\)</span>. Then, <span class="math display">\[\begin{align*}
E[Y|X=3] &amp;= \sum_{y=0}^3 y\left(\frac{7}{10}\right)^3\binom{3}{y}\left(\frac{3}{7}\right)^y \\
&amp;= (1)\left(\frac{7}{10}\right)^3\binom{3}{1}\left(\frac{3}{7}\right)^1 + (2)\left(\frac{7}{10}\right)^3\binom{3}{2}\left(\frac{3}{7}\right)^2 + (3)\left(\frac{7}{10}\right)^3\binom{3}{3}\left(\frac{3}{7}\right)^3 \\
&amp;= \frac{9}{10} = 0.9.
\end{align*}\]</span></li>
<li>Following the same process as above, we first get that the general conditional distribution is given by <span class="math display">\[p_{Y|X}(y|x) = \frac{\frac{44800}{854769} \frac{1}{(x-y)!y!} \left(\frac{21}{10}\right)^x\left(\frac{3}{7}\right)^{y}}{\frac{44800}{854769} \frac{3^{x}}{(x)!}} = \binom{x}{y}\left(\frac{7}{10}\right)^x\left(\frac{3}{7}\right)^y,\]</span> for <span class="math inline">\(y\in\{0,\dots,x\}\)</span>. Then the expected value of <span class="math inline">\(E[Y|X]\)</span> can be found as <span class="math display">\[\begin{align*}
E[Y|X] &amp;= \sum_{y=0}^x y\binom{x}{y}\left(\frac{7}{10}\right)^x\left(\frac{3}{7}\right)^y.
\end{align*}\]</span></li>
<li>We have <span class="math display">\[\begin{align*}
E[Y|X] &amp;= \sum_{y=0}^x y\binom{x}{y}\left(\frac{7}{10}\right)^x\left(\frac{3}{7}\right)^y \\
&amp;= \sum_{y=1}^x y\binom{x}{y}\left(\frac{7}{10}\right)^x\left(\frac{3}{7}\right)^y \\
&amp;= \sum_{y=1}^x x\binom{x-1}{y-1}\left(\frac{7}{10}\right)^x\left(\frac{3}{7}\right)^y \\
&amp;= \frac{3x}{10}\sum_{y=1}^x \binom{x-1}{y-1}\left(\frac{7}{10}\right)^{x-1}\left(\frac{3}{7}\right)^{y-1} \\
&amp;= \frac{3x}{10}\sum_{k=0}^{r} \binom{r}{k}\left(\frac{7}{10}\right)^r\left(\frac{3}{7}\right)^{k} \\
&amp;= \frac{3x}{10}\sum_{k=0}^{r} p_{Y|X}(k|r) \\
&amp;= \frac{3x}{10}.
\end{align*}\]</span></li>
<li>We have seen that <span class="math inline">\(E[Y|X=3] = 0.9\)</span>. As a result, using the previously derived conditional probability distribution, <span class="math display">\[\begin{align*}
\text{var}(Y|X=3) &amp;= \sum_{y=0}^3 (y-0.9)^2\left(\frac{7}{10}\right)^3\binom{3}{y}\left(\frac{3}{7}\right)^y \\
&amp;= 0.9^2\left(\frac{7}{10}\right)^3\binom{3}{0}\left(\frac{3}{7}\right)^0 + (0.1)^2\left(\frac{7}{10}\right)^3\binom{3}{1}\left(\frac{3}{7}\right)^1 \\
&amp;\quad + (1.1)^2\left(\frac{7}{10}\right)^3\binom{3}{2}\left(\frac{3}{7}\right)^2 + (2.1)^2\left(\frac{7}{10}\right)^3\binom{3}{3}\left(\frac{3}{7}\right)^3 \\
&amp;= 0.63
\end{align*}\]</span></li>
</ol>
</div>
</div>
</div>
</div>
</section>
<section id="conditional-expectations-as-random-variables" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="conditional-expectations-as-random-variables"><span class="header-section-number">7.2</span> Conditional Expectations as Random Variables</h2>
<p>Since <span class="math inline">\(E[X|Y]\)</span> is a function of an unknown random quantity, <span class="math inline">\(Y\)</span>, <span class="math inline">\(E[X|Y]\)</span> is also a random variable.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> It is a transformation of <span class="math inline">\(Y\)</span>, and as such, it will have some distribution, some expectation, and some variance itself. This is often a confusing concept when it is first introduced, so to recap:</p>
<ul>
<li><span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are both random variables;</li>
<li><span class="math inline">\(E[X]\)</span> and <span class="math inline">\(E[Y]\)</span> are both constant, numerical values describing the distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>;</li>
<li><span class="math inline">\(E[X|Y=y]\)</span> and <span class="math inline">\(E[Y|X=x]\)</span> are each numeric constants which summarize the distribution of <span class="math inline">\(X|Y=y\)</span> and <span class="math inline">\(Y|X=x\)</span> respectively;</li>
<li><span class="math inline">\(E[X|Y]\)</span> and <span class="math inline">\(E[Y|X]\)</span> are functions of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, respectively, and can as such be seen as transformations of (and random quantities depending on) <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> respectively.</li>
</ul>
<p>We do not often think of the distribution of <span class="math inline">\(E[X|Y]\)</span> directly, however, there are very useful results regarding its expected value and its variance, which will commonly be exploited. If we take the expected value of <span class="math inline">\(E[X|Y]\)</span> we will find that <span class="math inline">\(E[E[X|Y]] = E[X]\)</span>. Note that since <span class="math inline">\(E[X|Y] = g(Y)\)</span> for some transformation, <span class="math inline">\(g\)</span>, the outer expectation is taken with respect to the distribution of <span class="math inline">\(Y\)</span>. Sometimes when this may get confusing we will use notation to emphasize this fact, specifically, <span class="math inline">\(E_Y[E_{X|Y}[X|Y]] = E_X[X]\)</span>. This notation is not necessary, but it can clarify when there is much going on, and is a useful technique to fallback on.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Law of Total Expectation
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any random quantities, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the Law of Total Expectation states that <span class="math display">\[E[X] = E[E[X|Y]].\]</span> That is, if we first compute the conditional expectation of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y\)</span>, then take the expected value of this quantity, we compute <span class="math inline">\(E[X]\)</span>.</p>
</div>
</div>
<p>In the same way that it is sometimes easier to first condition on <span class="math inline">\(Y\)</span> in order to compute the marginal distribution of <span class="math inline">\(X\)</span> via applications of the law of total probability, so too can it be easier to first work out conditional expectations, and then take the expected value of the resulting expression.</p>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof of the Law of Total Expectation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To prove that law of total expectation, we note that <span class="math inline">\(E[X|Y]\)</span> is a random function of <span class="math inline">\(Y\)</span>. As a result, we can apply the LOTUS to <span class="math inline">\(E[X|Y]\)</span> as a function of <span class="math inline">\(Y\)</span> when we take <span class="math inline">\(E[E[X|Y]]\)</span>. Doing so yields, <span class="math display">\[\begin{align*}
E_Y[E[X|Y]] &amp;= \sum_{y\in\mathcal{Y}} E[X|Y]p_Y(y) \\
&amp;= \sum_{y\in\mathcal{Y}}\left(\sum_{x\in\mathcal{X}}xp_{X|Y}(x|Y)\right)p_Y(y) \\
&amp;= \sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}x\frac{p_{X,Y}(x,y)}{p_Y(y)}p_Y(y)\\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}xp_{X,Y}(x,y)\\
&amp;= \sum_{x\in\mathcal{X}} xp_X(x)\\
&amp;= E[X].\end{align*}\]</span> The remainder of the proof, following an application of the LOTUS relies upon manipulating summations.</p>
</div>
</div>
</div>
<div id="exm-law-of-total-expectation" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.2 (Charles Crochet Mistakes)</strong></span> While Charles came to understand the expected number of mistakes being made given a certain number of crochet lines being complete, it is easier for Charles to consider this on the basis of hourly errors than conditional hourly errors. Knowing that <span class="math display">\[p_{X,Y}(x,y) = \frac{44800}{854769} \frac{1}{(x-y)!y!} \left(\frac{21}{10}\right)^x\left(\frac{3}{7}\right)^{y}, \]</span> for <span class="math inline">\(x \in \{1,2,3,\dots,10\}\)</span> and <span class="math inline">\(y \in\{0,1,2,\dots,y\}\)</span>, that <span class="math display">\[p_X(x) = \frac{44800}{854769} \frac{3^x}{x!}, \quad x\in\{1,2,3,\dots,10\},\]</span> and that <span class="math inline">\(E[Y|X] = \frac{3X}{10}\)</span>, what is <span class="math inline">\(E[Y]\)</span>?</p>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Here we can apply the law of total expectation. We have that <span class="math inline">\(E[Y] = E[E[Y|X]] = E\left[\frac{3X}{10}\right] = \frac{3}{10}E[X]\)</span>. Thus, we need to work out <span class="math inline">\(E[X]\)</span>, which can be done via the probability mass function of <span class="math inline">\(X\)</span>. Specifically, <span class="math display">\[\begin{align*}
E[X] &amp;= \sum_{x=1}^{10} x\frac{44800}{854769} \frac{3^x}{x!} \\
&amp;= frac{44800}{854769} \sum_{x=1}^{10} \frac{3^x}{(x-1)!} \\
&amp;= frac{44800}{854769}\times\frac{67413}{1120} \\
&amp;= \frac{898840}{284923} \approx 3.155.
\end{align*}\]</span> Thus, in total, the expected value of <span class="math inline">\(Y\)</span> will be <span class="math display">\[\frac{3}{10}\times\frac{898840}{284923} = \frac{269652}{284923} \approx 0.946\]</span>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="conditional-variance" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="conditional-variance"><span class="header-section-number">7.3</span> Conditional Variance</h2>
<p>While the conditional expectation is used often, the conditional variance is less central to the study of random variables. As discussed, briefly, the conditional variance is given by the same variance relationship, replacing the marginal probability distribution with the conditional one. Just as with expectations <span class="math inline">\(\text{var}(X|Y=y)\)</span> is a numeric quantity given by <span class="math inline">\(E[(X-E[X|Y=y])^2|Y=y]\)</span> and <span class="math inline">\(\text{var}(X|Y)\)</span> is a random variable given by <span class="math inline">\(E[(X-E[X|Y])^2|Y]\)</span>. This means that we can consider the distribution, and critically the expected value of, <span class="math inline">\(\text{var}(X|Y)\)</span>. A core result relating to conditional expectations and variances connects these concepts.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Law of Total Variance
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we can write <span class="math display">\[\text{var}(X) = E[\text{var}(X|Y)] + \text{var}(E[X|Y]).\]</span> This result can be viewed as decomposing the variance of a random quantity into two separate components, and comes up again in later statistics courses. At this point we can view this as a method for connecting the marginal distribution through the conditional variance nad expectation.</p>
</div>
</div>
<div id="exm-law-of-total-variance" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.3 (Charles’ Crochet Consistency)</strong></span> Charles understands that the number of mistakes made per hour (<span class="math inline">\(Y\)</span>) given the number of rows crocheted per hour (<span class="math inline">\(X\)</span>) has <span class="math inline">\(E[Y|X] = 0.3X\)</span>. Moreover, the variability in this estimate is given by <span class="math inline">\(\text{var}(Y|X) = 0.21X\)</span>. Sadie has worked hard to find out that <span class="math display">\[E[X] = \frac{898840}{284923} \quad\text{ and }\quad \text{var}(X) = \frac{214410323010}{81181115929}.\]</span> Can Charles use this information to understand <span class="math inline">\(\text{var}(Y)\)</span>?</p>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We can apply the law of total variance. Specifically, <span class="math display">\[\text{var}(Y) = E[\text{var}(Y|X)] + \text{var}(E[Y|X]) = E[0.21X] + \text{var}(0.3X) = 0.21E[X] + 0.09\text{var}(X).\]</span> Plugging in the marginal values gives <span class="math display">\[\text{var}(Y) = 0.21\frac{898840}{284923} + 0.09\frac{214410323010}{81181115929} = \frac{730779688281}{811811159290} \approx 0.90.\]</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="joint-expectations" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="joint-expectations"><span class="header-section-number">7.4</span> Joint Expectations</h2>
<p>The final set of techniques to consider<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> relate to making use of the joint distribution between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Specifically, if we have any function of two random variables, say <span class="math inline">\(g(X,Y)\)</span> and we wish to find <span class="math inline">\(E[g(X,Y)]\)</span>. This follows in an exactly analogous derivation to what we have seen so far. In this case, we replace the marginal distribution with the joint distribution. The variance extends in the same manner as well.</p>
<div id="def-joint-expectation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7.2 (Joint Expectation)</strong></span> The joint expectation of a function (<span class="math inline">\(g\)</span>) of two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is written <span class="math inline">\(E[g(X,Y)]\)</span>. This is an expectation computed with respect to the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, giving <span class="math display">\[E[g(X,Y)] = \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g(x,y)p_{X,Y}(x,y).\]</span> The joint expectation captures the location of a multivariate function, and is readily extended to more than two random variables.</p>
</div>
<div id="def-joint-variance" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7.3 (Joint Variance)</strong></span> The joint variance of a function (<span class="math inline">\(g\)</span>) of two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is written <span class="math inline">\(\text{var}(g(X,Y))\)</span>. This is a variance computed with respect to the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, giving <span class="math display">\[\text{var}(g(X,Y)) = E[(g(X,Y) - E[g(X,Y)])^2].\]</span> The joint variance captures the spread of a multivariate function, and is readily extended to more than two random variables.</p>
</div>
<p>For instance, if we want to consider the product of two random variables, we could use this technique to determine <span class="math inline">\(E[XY]\)</span> and <span class="math inline">\(\text{var}(XY)\)</span>.</p>
<div id="exm-joint-expectation" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.4 (Door-to-Door Charity Chocolate Bars)</strong></span> Charles and Sadie are helping to raise money for a local charity, and to do so, they are going around house-to-house to sell chocolate bars. As they walk between the homes, they realize that depending on where in the city they are, the number of houses that they visit in a day is going to be vary. Moreover, each time they stop by a house, whether or not they will make a sale is uncertain. If, in any given hour, they take <span class="math inline">\(Y\)</span> to be the number of houses that they visit, and <span class="math inline">\(X\)</span> to be the number of chocolate bars that they sell, then they work out that the joint probability mass function of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is given by <span class="math display">\[p_{X,Y}(x,y) = \frac{2y - 1}{36(y + 1)}, \quad y\in\{1,\dots,6\}, x\in\{0,\dots,y\}.\]</span></p>
<p>What is the expected number of chocolate bars per house that the visit?</p>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We want <span class="math inline">\(E[g(X,Y)]\)</span> where <span class="math inline">\(g(X,Y) = \dfrac{X}{Y}\)</span>. Thus, using the defining relationship for joint probabilities we get <span class="math display">\[\begin{align*}
E[g(X,Y)] &amp;= E\left[\frac{X}{Y}\right] \\
&amp;= \sum_{y=1}^{6}\sum_{x=0}^{y} \frac{x}{y}\cdot\frac{2y - 1}{36(y + 1)} \\
&amp;= \sum_{y=1}^{6}\frac{2y-1}{36y(y + 1)}\sum_{x=0}^{y} x \\
&amp;= \sum_{y=1}^{6}\frac{2y-1}{36y(y + 1)}\cdot\frac{y(y+1)}{2} \\
&amp;= \sum_{y=1}^{6}\frac{2y-1}{72} \\
&amp;= \frac{1}{72}\left[2\sum_{y=1}^{6} y - \sum_{y=1}^6 1\right]\\
&amp;= \frac{1}{72}\left[42 - 6\right] = \frac{1}{2}.
\end{align*}\]</span> As a result, they sell <span class="math inline">\(0.5\)</span> chocolate bars per house that they visit, on average.</p>
</div>
</div>
</div>
</div>
<p>It is worth considering, briefly, the ways in which conditional and joint expectations interact. Namely, if we know that <span class="math inline">\(Y=y\)</span>, then the transformation <span class="math inline">\(g(X,y)\)</span> only has one random component, which is <span class="math inline">\(X\)</span>. As a result, taking <span class="math inline">\(E[g(X,Y)|Y=y] = E[g(X,y)|Y=y]\)</span>. If instead we use the conditional distribution without a specific value, we still have that <span class="math inline">\(Y\)</span> is fixed within the expression, it is just fixed to an unknown quantity. That is <span class="math inline">\(E[g(X,Y)|Y]\)</span> will be a function of <span class="math inline">\(Y\)</span>. We saw before that <span class="math inline">\(E[E[X|Y]] = E[X]\)</span>, and the same is true in the joint case. Thus, one technique for computing the joint expectation, <span class="math inline">\(g(X,Y)\)</span> is to first compute the conditional expectation, and then compute the marginal expectation of the resulting quantity.</p>
<div id="exm-joint-expectation-two" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.5 (Door-to-Door Charity Chocolate Bars, Marginally Easier)</strong></span> While walking around selling chocolate bars for charity, Charles and Sadie realize that it is fairly straightforward<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> to marginalize the joint probability mass function for the number of houses that they visit and the number of chocolate bars that they sell, since <span class="math inline">\(X\)</span> does not actually appear in the equation. That is, when <span class="math display">\[p_{X,Y}(x,y) = \frac{2y - 1}{36(y + 1)}, \quad y\in\{1,\dots,6\}, x\in\{0,\dots,y\},\]</span> taking the sum <span class="math inline">\(\sum_{x=0}^{y} p_{X,Y}(x,y) = (y+1)p_{X,Y}(x,y) = \dfrac{2y-1}{36}\)</span>. This gives the marginal probability distribution of <span class="math inline">\(Y\)</span>. They also realize that this has greatly simplified finding the conditional probability distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y\)</span>.</p>
<ol type="a">
<li>Find the expected value of the number of chocolate bars per house that they sell, given the number of houses they visit.</li>
<li>Use this result to determine the expected number of chocolate bars sold per visited house.</li>
</ol>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li>Note that <span class="math display">\[p_{X|Y}(x|y) = \frac{1}{y+1} \quad x \in \{0,1,\dots,y\}.\]</span> As a result, we can compute <span class="math display">\[E[\frac{X}{Y}|Y] \frac{1}{Y}E[X|Y]= \frac{1}{Y}\sum_{x=0}^{Y} \frac{x}{Y+1} = \frac{1}{Y(Y+1)}\cdot\frac{Y(Y+1)}{2} = \frac{1}{2}.\]</span></li>
<li>Note that, <span class="math display">\[E\left[\frac{Y}{X}\right] = E\left[E\left[\left.\frac{Y}{X}\right|Y\right]\right] = E[0.5] = 0.5,\]</span> just as before.</li>
</ol>
</div>
</div>
</div>
</div>
<section id="linear-combinations-of-random-variables" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="linear-combinations-of-random-variables"><span class="header-section-number">7.4.1</span> Linear Combinations of Random Variables</h3>
<p>With this relationship, we can ask about taking combinations of random variables. For instance, if we have two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we can use this framework to understand how <span class="math inline">\(X + Y\)</span> behaves. An application of these rules with the function <span class="math inline">\(g(X,Y) = X + Y\)</span> gives <span class="math inline">\(E[X+Y] = E[X] + E[Y]\)</span>, and that <span class="math inline">\(\text{var}(X + Y) = \text{var}(X) + \text{var}(Y) + 2E[(X-E[X])(Y - E[Y])]\)</span>. Thus, we see that expectations are linear over combinations of random variables, however, variances are not. The term <span class="math inline">\(E[(X-E[X])(Y - E[Y])]\)</span> is called the <strong>covariance</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and it is a measure of how related <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> happen to be.</p>
<div id="def-covariance" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7.4 (Covariance)</strong></span> The covariance of two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is given by <span class="math inline">\(\text{cov}(X,Y) = E[(X - E[X])(Y - E[Y])]\)</span>. The covariance measures the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, where a positive covariance value means that as <span class="math inline">\(X\)</span> increases, <span class="math inline">\(Y\)</span> will also increase on average (and vice versa). A negative covariance means that as <span class="math inline">\(X\)</span> increases, <span class="math inline">\(Y\)</span> will decrease on average (and vice versa).</p>
</div>
<p>The covariance behaves similarly to the variance. We can see directly from the definition that <span class="math inline">\(\text{cov}(X,X) = \text{var}(X)\)</span>. Moreover, using similar arguments to those used for the variance, we can show that <span class="math display">\[\text{cov}(aX+b,cY+d) = ac\text{cov}(X,Y).\]</span> Covariances remain linear, so that <span class="math display">\[\begin{multline*}\text{cov}(X+Y,X+Y+Z)=\text{cov}(X,X)+\text{cov}(X,Y)+\text{cov}(X,Z)\\ +\text{cov}(Y,X)+\text{cov}(Y,Y)+\text{cov}(Y,Z).\end{multline*}\]</span> These make covariances somewhat nicer to deal with than variances, and on occasion it may be easier to think of variances as covariances with themselves.</p>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proofs for the Expectation and Variance of Linear Combinations of Random Variables
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>With <span class="math inline">\(g(X,Y) = X+Y\)</span>, we can consider applying the defining relationship for joint expectations. That is <span class="math display">\[\begin{align*}
E[X+Y] &amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}(x+y)p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}x\sum_{y\in\mathcal{Y}}p_{X,Y}(x,y) + \sum_{y\in\mathcal{Y}}y\sum_{x\in\mathcal{X}}p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}xp_X(x) + \sum_{y\in\mathcal{Y}}yp_Y(y) \\
&amp;= E[X] + E[Y].\end{align*}\]</span></p>
<p>For the variances, we apply the variance relationship, giving <span class="math display">\[\begin{align*}
E[(X+Y-E[X]-E[Y])^2] &amp;= E[((X-E[X])+(Y-E[Y]))^2] \\
&amp;= E[(X-E[X])^2] + E[(Y-E[Y])^2] \\
&amp;\quad+ 2E[(X-E[X])(Y-E[Y])] \\
&amp;= \text{var}(X) + \text{var}(Y) + 2E[(X-E[X])(Y-E[Y])].\end{align*}\]</span> Rewriting the covariance in more common terms gives, <span class="math display">\[\text{var}(X+Y) = \text{var}(X) + \text{var}(Y) + 2\text{cov}(X,Y).\]</span></p>
</div>
</div>
</div>
<div id="exm-linear-combination-of-RV" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.6 (Charles and Sadie’s Orchard Trip)</strong></span> Charles and Sadie adore visiting orchards when the season is right. They are happy to go pick fruit, and then combine everything that they manage together at the end. On one trip to a favourite orchard of theirs they decide to split up and pick separately. This works well enough that on the trip home they decide to start analyzing this behaviour. They take <span class="math inline">\(X\)</span> to be the quantity of fruit picked by Sadie, and <span class="math inline">\(Y\)</span> to be the quantity of fruit picked by Charles. Suppose that they figure that the number of kilograms of fruit jointly picked by them is represented by the probability mass function <span class="math display">\[p_{X,Y}(x,y) = \frac{14xy}{251(x + y)}, \quad x,y\in\{1,\dots,4\}.\]</span></p>
<ol type="a">
<li>What quantity of fruit does Sadie pick on average? Charles?</li>
<li>What is the variance of fruit picked by Sadie? Charles?</li>
<li>What is the covariance between the amount of fruit that Sadie and Charles each pick?</li>
<li>What is the expected total fruit picked between both Charles and Sadie?</li>
<li>What is the variance of the total fruit picked between both Charles and Sadie?</li>
</ol>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li>Note that the joint distribution is symmetric in <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> so they will have equal expected value. We solve for <span class="math inline">\(E[X]\)</span> and note that <span class="math inline">\(E[Y]\)</span> will be the same. <span class="math display">\[\begin{align*}
E[X] &amp;= \sum_{x=1}^4 xp_X(x) \\
&amp;= \sum_{x=1}^4 x\sum_{y=1}^4 p_{X,Y}(x, y) \\
&amp;= \sum_{x=1}^4\sum_{y=1}^4 \frac{14x^2y}{251(x + y)} \\
&amp;= \frac{700}{251} \approx 2.789.
\end{align*}\]</span></li>
<li>For the variance we note that they will also be equivalent between the two individuals. Since we have <span class="math inline">\(E[X]\)</span> already, we simply compute <span class="math inline">\(E[X^2]\)</span> which is given by <span class="math display">\[\begin{align*}
E[X^2] &amp;= \sum_{x=1}^4 x^2p_X(x) \\
&amp;= \sum_{x=1}^4 x^2\sum_{y=1}^4 p_{X,Y}(x, y) \\
&amp;= \sum_{x=1}^4\sum_{y=1}^4 \frac{14x^3y}{251(x + y)} \\
&amp;= \frac{11169}{1255} \approx 8.900.
\end{align*}\]</span> Thus, the variance is going to be given by <span class="math display">\[\text{var}(X) = \frac{11169}{1255} - \left(\frac{700}{251}\right)^2 = \frac{353419}{315005}.\]</span></li>
<li>The covariance is computable using the joint distribution directly, giving <span class="math display">\[\begin{align*}
\text{cov}(X,Y) &amp;= E[(X-E[X])(Y-E[Y])] \\
&amp;= \sum_{x=1}^4\sum_{y=1}^4 \left(X-\frac{700}{251}\right)\left(Y-\frac{700}{251}\right)\frac{14xy}{251(x + y)} \\
&amp;= \frac{17581}{315005} \approx 0.059
\end{align*}\]</span></li>
<li>We want <span class="math inline">\(E[X+Y] = E[X] + E[Y] = \frac{1400}{251}\)</span>. This could also be computed directly, <span class="math display">\[\begin{align*}
E[X+Y] &amp;= \sum_{x=1}^4\sum_{y=1}^4 (x+y)\frac{14xy}{251(x + y)} \\
&amp;= \frac{14}{251}\sum_{x=1}^4\sum_{y=1}^{4}xy \\
&amp;= \frac{14}{251}\times 100 = \frac{1400}{251}.
\end{align*}\]</span></li>
<li>We want <span class="math display">\[\text{var}(X+Y) = \text{var}(X) + \text{var}(Y) + 2\text{cov}(X,Y) = 2\times\frac{353419}{315005} + 2\times\frac{17581}{315005} = \frac{148400}{63001}.\]</span></li>
</ol>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="expectations-when-random-variables-are-independent" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="expectations-when-random-variables-are-independent"><span class="header-section-number">7.5</span> Expectations when Random Variables are Independent</h2>
<p>Whenever we can assume independence of random quantities, we can greatly simplify the expressions we are dealing with. Recall that the key defining relationship with independence is that <span class="math inline">\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\)</span>. Suppose then that we can write <span class="math inline">\(g(X,Y) = g_X(X)h_Y(Y)\)</span>. For instance, for the covariance we have <span class="math inline">\(g(X,Y)=(x-E[X])(Y-E[Y])\)</span> and so <span class="math inline">\(g_X(X) = X-E[X]\)</span> and <span class="math inline">\(h_Y(Y) = Y-E[Y]\)</span>. If we want to compute <span class="math inline">\(E[g(X,Y)]\)</span> then we get <span class="math display">\[\begin{align*}
E[g(X,Y)] &amp;= E[g_X(X)h_Y(Y)] \\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g_X(x)h_Y(y)p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g_X(x)h_Y(y)p_X(x)p_Y(y) \\
&amp;=\sum_{x\in\mathcal{X}}g_X(x)p_X(x)\sum_{y\in\mathcal{Y}}h_Y(y)p_Y(y)\\
&amp;= E[g_X(X)]E[h_Y(Y)].\end{align*}\]</span> Thus, whenever random variables are independent, we have the ability to separate them over their expectations. Stated succinctly, whenever <span class="math inline">\(X\perp Y\)</span>, then <span class="math display">\[E[g_X(X)h_Y(Y)] = E[g_X(X)]E[h_Y(Y)].\]</span></p>
<div id="exm-independent-rv-expectation" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.7 (Sadie and Charles Turn back To Dice)</strong></span> With a more thorough understanding of joint distributions, Sadie and Charles turn back to games of chance. They are considering games where dice are rolled a set number of times, and then the total sum is recorded across all of the rolls. They want to understand both what happens in expectation, and the variability of these trials.</p>
<ol type="a">
<li>Suppose that <span class="math inline">\(X_1\)</span> is a single roll of a die. What is the mean and variance of the roll?</li>
<li>Suppose that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are the results from two independent rolls of a die. What is the mean and variance of <span class="math inline">\(X_1 + X_2\)</span>.</li>
<li>Suppose that <span class="math inline">\(X_1,\dots,X_n\)</span> are the results from <span class="math inline">\(n\)</span> independent rolls of a die. What is the mean and variance of <span class="math inline">\(\sum_{i=1}^n X_i\)</span>?</li>
<li>Suppose that <span class="math inline">\(X_1,\dots,X_n\)</span> are the results from <span class="math inline">\(n\)</span> independent rolls of a die. Moreover, take <span class="math inline">\(Z\)</span> to be the result of an additional independent die roll. What is the mean and variance of <span class="math inline">\(Z\times \sum_{i=1}^n X_i\)</span>?</li>
</ol>
<div class="solution callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li><p>We know that <span class="math inline">\(X_1\)</span> takes on the values in <span class="math inline">\(\{1,\dots,6\}\)</span> with equal probability each. Thus we have <span class="math display">\[\begin{align*}
E[X_1] &amp;= \sum_{x=1}^6 \frac{x}{6} = \frac{21}{6} = 3.5 \\
E[X_1^2] &amp;= \sum_{x=1}^6 \frac{x^2}{6} = \frac{91}{6} \\
\text{var}(X_1) &amp;= \frac{91}{6} - \left(\frac{21}{6}\right)^2 = \frac{35}{12}.
\end{align*}\]</span></p></li>
<li><p>Note that because <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, we get <span class="math display">\[\begin{align*}
E[X_1 + X_2] &amp;= E[X_1] + E[X_2] \\
&amp;= 2\frac{21}{6} = 7.\\
\text{var}(X_1 + X_2) &amp;= \text{var}(X_1) + \text{var}(X_2) \\
&amp;= 2\frac{35}{12} = \frac{35}{6}.
\end{align*}\]</span></p></li>
<li><p>Note that because <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, we get <span class="math display">\[\begin{align*}
E[\sum_{i=1}^n X_i] &amp;= \sum_{i=1}^n E[X_i]\\
&amp;= \frac{21n}{6}\\
\text{var}(\sum_{i=1}^nX_i) &amp;= \sum_{i=1}^n\text{var}(X_i)\\
&amp;= \frac{35n}{12}.
\end{align*}\]</span></p></li>
<li><p>Note that <span class="math inline">\(Z\)</span> and <span class="math inline">\(X_1,\dots,X_n\)</span> are all independent. As a result if we take <span class="math inline">\(T = \sum_{i=1}^n X_i\)</span>, then <span class="math inline">\(T \perp Z\)</span> and so <span class="math inline">\(E[TZ] = E[T]E[Z]\)</span>. Thus, from (a), (b), and (c) we get <span class="math inline">\(E[ZT] = \frac{21}{6}\times\frac{21n}{6} = \frac{49n}{4}\)</span>.</p></li>
</ol>
<p>For the variance note that we get <span class="math display">\[\text{var}(TZ) = E[(TZ)^2] - E[TZ]^2 = E[T^2]E[Z^2] - E[TZ]^2.\]</span> For <span class="math inline">\(E[T^2]\)</span> and <span class="math inline">\(E[Z^2]\)</span> note that <span class="math inline">\(E[T^2] = \text{var}(T) + E[T]^2\)</span>, and similarly for <span class="math inline">\(Z\)</span>. Thus <span class="math display">\[E[T^2] = \frac{35n}{12} + \left(\frac{21n}{6}\right)^2,\]</span> and <span class="math display">\[E[Z^2] = \frac{91}{6},\]</span> thus <span class="math display">\[\text{var}(TZ) = \left(\frac{35n}{12} + \left(\frac{21n}{6}\right)^2\right)\left(\frac{91}{6}\right) - \left( \frac{49n}{4}\right)^2 = \frac{245n(21n + 26)}{144}.\]</span></p>
</div>
</div>
</div>
</div>
<p>Consider what this means for the covariance between independent random variables. If <span class="math inline">\(X\perp Y\)</span> then <span class="math display">\[\text{cov}(X,Y) = E[(X-E[X])(Y-E[Y])] = E[X-E[X]]E[Y-E[Y]].\]</span> Note that <span class="math inline">\(E[X - E[X]] = E[X] - E[X] = 0\)</span>, and the same for <span class="math inline">\(E[Y - E[Y]]\)</span>. Thus, if <span class="math inline">\(X \perp Y\)</span> then <span class="math inline">\(\text{cov}(X, Y) = 0\)</span>. That is to say, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(\text{cov}(X,Y)=0\)</span>. It is critical to note that this relationship does <strong>not</strong> go both ways. You are able to have <span class="math inline">\(\text{cov}(X,Y) = 0\)</span> even if <span class="math inline">\(X\not\perp Y\)</span>.</p>
<p>While the covariance is interesting in and of itself, the result allows us to simplify the expression for the variance of a sum of two random variables. Specifically, for independent random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> we also must have that <span class="math inline">\(\text{var}(X+Y)=\text{var}(X)+\text{var}(Y)\)</span>. This further extends to more than two random variables, where if (for instance) we have <span class="math inline">\(X_1,X_2,\dots,X_n\)</span> all independent, we get both that <span class="math display">\[E\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n E[X_i],\]</span> and that <span class="math display">\[\text{var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{var}(X_i).\]</span> These are relationships that we will use <strong>heavily</strong> once we begin to consider statistics. Note, this extension to more than two random variables applies to all of the concepts discussed throughout this chapter.</p>
<p>In order to do so, the relevant joint distribution, or conditional distribution would need to be substituted into the definitions. Often the complexity here becomes a matter of keeping track of which quantities are random, and which are not. For instance, if we have <span class="math inline">\(X,Y,Z\)</span> as random variables, then <span class="math inline">\(E[X|Y,Z]\)</span> is a random function of <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>. We will still have that <span class="math inline">\(E[E[X|Y,Z]] = E[X]\)</span>, however, the outer expectation is now the joint expectation with respect to <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>. As a result, we can also write <span class="math inline">\(E[E[X|Y,Z]|Y]\)</span>. The first expectation will be with respect to <span class="math inline">\(X|Y,Z\)</span>, while the outer expectation is with respect to <span class="math inline">\(Z|Y\)</span>. This is a useful demonstration for when making the distribution of the expectation explicit may help clarify what is being computed. In general, the innermost expectations will always have more conditioning variables than the outer ones. Each time we step out, we peel back one of hte conditional variables until the outermost is either a marginal (or joint). This may help to keep things clear.</p>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div class="exr-7.1">
<p>Find the variance and standard deviation of the sum obtained in tossing a pair of standard dice. (Note, this was <a href="chapter6.html#exr-6.1" class="quarto-xref">Exercise&nbsp;<span>6.1</span></a> as well; however, now we can use a different technique for it.)</p>
</div>
<div id="exr-7.2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.1</strong></span> Consider the joint probability mass function of two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, given by <span class="math display">\[P(X=x, Y=y) = \frac{1}{150}(x + y), 1\leq x, y\leq 5.\]</span></p>
<ol type="a">
<li>Find <span class="math inline">\(E[X|Y=2]\)</span>.</li>
<li>Find <span class="math inline">\(E[Y|X]\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(Y|X)\)</span>.</li>
</ol>
</div>
<div id="exr-7.3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.2</strong></span> Consider the joint probability mass function of two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, given by <span class="math display">\[P(X=x, Y=y) = \frac{1}{12}(y - x)^2, 1\leq x, y\leq 3.\]</span></p>
<ol type="a">
<li>Find <span class="math inline">\(E[X|Y=1]\)</span>.</li>
<li>Find <span class="math inline">\(E[Y|X]\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(Y|X)\)</span>.</li>
<li>Find <span class="math inline">\(\text{cov}(X,Y)\)</span>.</li>
</ol>
</div>
<div id="exr-7.4" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.3</strong></span> Consider the following joint probability mass function represented as a contingency table:</p>
<p><span class="math display">\[
\begin{array}{c|ccc}
    &amp; Y = 1 &amp; Y = 2 &amp; Y = 3 \\
\hline
X = 1 &amp; 0.1 &amp; 0.2 &amp; 0.3 \\
X = 2 &amp; 0.2 &amp; 0.1 &amp; 0.1 \\
\end{array}
\]</span></p>
<ol type="a">
<li>Find <span class="math inline">\(E[X]\)</span>.</li>
<li>Find <span class="math inline">\(E[Y]\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(X)\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(Y)\)</span>.</li>
<li>Find <span class="math inline">\(\text{cov}(X,Y)\)</span>.</li>
<li>Find the expected value and variance of <span class="math inline">\(X+Y\)</span>.</li>
</ol>
</div>
<div id="exr-7.5" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.4</strong></span> Suppose that a particular disease is associated with two common types of genetic mutations, say type <span class="math inline">\(A\)</span> and type <span class="math inline">\(B\)</span>. Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> correspond to the random variables which count the locations at which each type of mutation has occurred. In order for a type <span class="math inline">\(B\)</span> mutation to occur, a type <span class="math inline">\(A\)</span> must have also occurred at the same location, and so we can say that <span class="math display">\[P(B=b|A=a) = \binom{a}{b}(0.25)^b(0.75)^{a-b}, \quad b\in\{0,1,2,\dots, a\}.\]</span> Moreover, suppose that <span class="math display">\[P(A=a) = \frac{10-a}{45} \quad a\in\{0,1,2,3,4,5\}.\]</span></p>
<ol type="a">
<li>Find <span class="math inline">\(E[B|A]\)</span>.</li>
<li>Find <span class="math inline">\(E[B]\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(B|A)\)</span>.</li>
<li>Find <span class="math inline">\(\text{var}(B)\)</span>.</li>
</ol>
</div>
<div id="exr-7.6" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.5</strong></span> Suppose a factory produces two types of products: Widgets and Gadgets. Let <span class="math inline">\(W\)</span> and <span class="math inline">\(G\)</span> represent the random variables denoting the number of units produced for each type, in a particular hour. Suppose that the following is observed as the joint probability mass function <span class="math display">\[P(W=w, G=g) = \frac{1}{80}, \quad w \in \{1,2,3,\dots,8\}, g \in \{1,2,3,\dots,10\}.\]</span></p>
<p>Find both the mean and variance of <span class="math inline">\(W+G\)</span>.</p>
</div>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>For instance, you might ask “how long do we expect a patient to live, given that they received a particular treatment?” or “how much do we expect this house to sell for, given it has a certain square footage?” or “how many goals do we expect this hockey team to score, given their current lineup?” A large number of questions which we may hope to answer using data can be framed as a question of conditional expectation.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>It is useful to keep in mind that anytime we do <em>anything</em> with a random variable, mathematically, we produce an additional random variable. If we think of a random variable as being some mathematical variable whose value depends on the results of an experiment, then if we take that value and apply a function to it we have a <em>new</em> value whose results also depend on the results of an experiment.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>At least, for now.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Comparatively speaking!<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          trigger: 'click',
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          positionFixed: true,
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notes/chapter6.html" class="pagination-link  aria-label=" &lt;span="" expected="" value,="" location="" summaries,="" and="" measures="" of="" variability&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Expected Value, Location Summaries, and Measures of Variability</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notes/chapter8.html" class="pagination-link" aria-label="<span class='chapter-number'>8</span>&nbsp; <span class='chapter-title'>The Named Discrete Distributions</span>">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Named Discrete Distributions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>